{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12808614,"sourceType":"datasetVersion","datasetId":8099076},{"sourceId":12814286,"sourceType":"datasetVersion","datasetId":8102851}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/phamhoang1909/extract-frame?scriptVersionId=257141227\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!git clone https://github.com/hein-nkhh/tri-modal-keyframe-extraction.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:18:22.199684Z","iopub.execute_input":"2025-08-20T17:18:22.200113Z","iopub.status.idle":"2025-08-20T17:18:23.0328Z","shell.execute_reply.started":"2025-08-20T17:18:22.200088Z","shell.execute_reply":"2025-08-20T17:18:23.032095Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'tri-modal-keyframe-extraction'...\nremote: Enumerating objects: 51, done.\u001b[K\nremote: Counting objects: 100% (51/51), done.\u001b[K\nremote: Compressing objects: 100% (46/46), done.\u001b[K\nremote: Total 51 (delta 4), reused 51 (delta 4), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (51/51), 1.41 MiB | 9.28 MiB/s, done.\nResolving deltas: 100% (4/4), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:18:23.034085Z","iopub.execute_input":"2025-08-20T17:18:23.03431Z","iopub.status.idle":"2025-08-20T17:18:23.039673Z","shell.execute_reply.started":"2025-08-20T17:18:23.034289Z","shell.execute_reply":"2025-08-20T17:18:23.038952Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%%writefile /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/main.py\nfrom feature_extraction.color_features import color_feature_extraction\nfrom feature_extraction.image_features import image_feature_extraction\nfrom feature_extraction.content_features import content_feature_extraction\nfrom feature_extraction.cross_modal_features import feature_level_fusion\nfrom clustering import cluster_frames\nfrom frame_selection import candidate_frame_selection\nimport time\n\ndef main():\n\n    start = time.time()\n\n    # video_folder = \"evaluation/\"\n    # dataset_name = \"Summe\"\n\n    full_path = \"/kaggle/input/sample-video\"\n\n    print(\"Feature Extraction is started...\")\n\n    print(\"Extracting Color Features...\")\n    color_feature_extraction.extract_color_features(full_path, frame_interval=1)\n\n    print(\"Extracting Image Features...\")\n    image_feature_extraction.extract_image_features(full_path, frame_interval=1)\n\n    print(\"Extracting Content Features...\")\n    content_feature_extraction.extract_content_features(full_path, frame_interval=1)\n\n    print(\"Fusing the Features...\")\n    feature_level_fusion.fuse_features()\n\n    print(\"Clustering the Fused Features...\")\n    cluster_frames.cluster(visualize=False)\n\n    print(\"Selecting the Candidate Keyframes...\")\n    candidate_frame_selection.find_candidate_keyframes(full_path)\n\n    end = time.time()\n    print(\"Time passed:\" + str(end-start))\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:18:23.040328Z","iopub.execute_input":"2025-08-20T17:18:23.040522Z","iopub.status.idle":"2025-08-20T17:18:23.050538Z","shell.execute_reply.started":"2025-08-20T17:18:23.040508Z","shell.execute_reply":"2025-08-20T17:18:23.049883Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/main.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# from multiprocessing import set_start_method\n# try:\n#     set_start_method(\"spawn\")\n# except RuntimeError:\n#     pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:18:23.05222Z","iopub.execute_input":"2025-08-20T17:18:23.052653Z","iopub.status.idle":"2025-08-20T17:18:23.059633Z","shell.execute_reply.started":"2025-08-20T17:18:23.052636Z","shell.execute_reply":"2025-08-20T17:18:23.059056Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"%%writefile /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/feature_extraction/content_features/content_feature_extraction.py\nimport os\nimport cv2\nimport torch\nfrom PIL import Image\nfrom tqdm import tqdm\nimport csv\nfrom multiprocessing import Pool, set_start_method\nfrom transformers import MllamaForConditionalGeneration, AutoProcessor\nfrom transformers import BitsAndBytesConfig\nfrom feature_extraction.content_features import content_embeddings\n\n\ndef get_videos(directory='../../test_videos'):\n    \"\"\"\n    Retrieves video file paths from the specified directory.\n    \"\"\"\n    video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.flv')\n\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n        print(f\"Created directory: {directory}\")\n\n    video_files = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.lower().endswith(video_extensions):\n                video_files.append(os.path.join(root, file))\n\n    if not video_files:\n        print(f\"No video files found in '{directory}'. Please add videos to process.\")\n\n    return video_files\n\n\ndef  initialize_model():\n    \"\"\"\n    Initializes the Llama 3.2-11B-Vision-Instruct model and processor with quantization.\n    \"\"\"\n    model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n\n    config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_compute_dtype=torch.bfloat16,\n    )\n    \n    # Set quantization configuration\n    # quantization_config = BitsAndBytesConfig(\n    #     load_in_4bit=True,\n    #     bnb_4bit_quant_type='nf4',\n    #     bnb_4bit_use_double_quant=True,\n    #     bnb_4bit_compute_dtype=torch.bfloat16\n    # )\n\n    # Load the model with quantization\n    model = MllamaForConditionalGeneration.from_pretrained(\n        model_id,\n        # quantization_config=quantization_config,\n        # low_cpu_mem_usage=True,\n        # torch_dtype=torch.bfloat16,\n        quantization_config=config,\n        device_map=\"auto\"\n    )\n    model.eval()\n\n    # Compile the model for potential speed gains (requires Torch 2.0+)\n    model = torch.compile(model, mode=\"default\")\n\n    # Load the processor\n    processor = AutoProcessor.from_pretrained(model_id)\n\n    return model, processor, torch.device('cuda')\n\n\ndef generate_description(frames, model, processor, device):\n    \"\"\"\n    Generates content descriptions for a list of frames using the model.\n    If the model returns a response indicating it does not see the image,\n    we replace the description with a default placeholder.\n    \"\"\"\n    # Convert each frame from BGR to RGB using slicing (usually faster than cv2.cvtColor)\n    images = [Image.fromarray(frame[..., ::-1]) for frame in frames]\n\n    # Since the prompt is identical for every image, compute it once:\n    prompt = processor.apply_chat_template(\n        [{\"role\": \"user\", \"content\": [{\"type\": \"image\"},\n                                       {\"type\": \"text\", \"text\": \"In one sentence, describe the visible content of this provided image: \"}] }],\n        add_generation_prompt=True\n    )\n    # Replicate the same prompt for each image (batch_size remains 1 for each call)\n    input_texts = [prompt] * len(images)\n\n    inputs = processor(\n        images=images,\n        text=input_texts,\n        add_special_tokens=False,\n        return_tensors=\"pt\",\n        padding=True\n    ).to(device)\n\n    prompt_lengths = inputs['input_ids'].ne(processor.tokenizer.pad_token_id).sum(dim=1)\n\n    with torch.inference_mode():\n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=30,\n            do_sample=False,  # greedy decoding\n            temperature=None,\n            top_p=None\n        )\n\n    descriptions = []\n    unwanted_tokens = [\"<|eot_id|>\", \"<|finetune_right_pad_id|>\"]\n\n    # Keywords that indicate the model did not \"see\" the image\n    no_image_keywords = [\n        \"have access to an image\",\n        \"no image provided\",\n        \"no image\",\n        \"not seeing\",\n        \"image is blank\",\n        \"share the image with me\",\n        \"see an image\",\n        \"access images\",\n        \"access the images\",\n        \"unable to view or describe\",\n        \"not able to view the image\",\n        \"to view or access images\",\n        \"see the image\",\n        \"Unfortunately\",\n    ]\n\n    for i, output in enumerate(outputs):\n        prompt_length = prompt_lengths[i]\n        response = processor.decode(output[prompt_length:], skip_special_tokens=True)\n        # Remove unwanted tokens manually\n        for t in unwanted_tokens:\n            response = response.replace(t, \"\")\n        response = response.strip()\n\n        if any(keyword in response.lower() for keyword in no_image_keywords):\n            response = \"No visible content\"\n\n        descriptions.append(response)\n\n    return descriptions\n\n\ndef process_videos_on_gpu(args):\n    \"\"\"\n    Processes the assigned videos on the given GPU.\n    Uses a background thread to prefetch frames while running inference.\n    \"\"\"\n    import threading\n    from queue import Queue, Empty\n\n    gpu_id, video_files, frame_interval = args\n\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n\n    model, processor, device = initialize_model()\n\n    all_results = []\n\n    for video_file in video_files:\n        video_name = os.path.splitext(os.path.basename(video_file))[0]\n        cap = cv2.VideoCapture(video_file)\n        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        results = []\n\n        pbar = tqdm(total=total_frames, desc=f\"Processing {video_name} on GPU {gpu_id}\", leave=False)\n\n        # Queue to hold prefetched frames (adjust maxsize as needed)\n        frame_queue = Queue(maxsize=20)\n        stop_event = threading.Event()\n\n        def read_frames():\n            idx = 0\n            while True:\n                ret, frame = cap.read()\n                if not ret:\n                    break\n                if idx % frame_interval == 0:\n                    frame_queue.put((idx, frame))\n                idx += 1\n                # Update progress bar as each frame is read.\n                pbar.update(1)\n            stop_event.set()\n\n        reader_thread = threading.Thread(target=read_frames)\n        reader_thread.start()\n\n        # Process frames as they become available.\n        while not (stop_event.is_set() and frame_queue.empty()):\n            try:\n                frame_idx, frame = frame_queue.get(timeout=1)\n            except Empty:\n                continue\n            try:\n                # Process a single frame (batch size = 1)\n                description = generate_description([frame], model, processor, device)[0]\n                results.append({\n                    'video_id': video_name,\n                    'frame_id': frame_idx,\n                    'description': description\n                })\n            except Exception as e:\n                print(f\"Error processing frame {frame_idx} of {video_name} on GPU {gpu_id}: {e}\")\n\n        reader_thread.join()\n        pbar.close()\n        cap.release()\n        all_results.extend(results)\n\n    del model\n    torch.cuda.empty_cache()\n\n    return all_results\n\n\ndef extract_content_features(video_path='../../test_videos', frame_interval=10):\n    \"\"\"\n    Retrieves videos, processes them in parallel across available GPUs, and saves\n    the frame descriptions to CSV. Finally, converts the descriptions to embeddings.\n    \"\"\"\n    # Ensure multiprocessing uses 'spawn' method\n    set_start_method('spawn', force=True)\n\n    # Step 1: Get list of video files\n    video_files = get_videos(video_path)\n    if not video_files:\n        return\n\n    # Determine the number of available GPUs\n    num_gpus = torch.cuda.device_count()\n\n    if num_gpus == 0:\n        print(\"No GPUs available. Exiting.\")\n        return\n\n    # Distribute videos across GPUs\n    video_chunks = [[] for _ in range(num_gpus)]\n    for idx, video_file in enumerate(video_files):\n        gpu_id = idx % num_gpus\n        video_chunks[gpu_id].append(video_file)\n\n    # Prepare arguments for multiprocessing\n    args_list = []\n    for gpu_id in range(num_gpus):\n        args_list.append((gpu_id, video_chunks[gpu_id], frame_interval))\n\n    # Use a multiprocessing Pool to process videos in parallel\n    with Pool(processes=num_gpus) as pool:\n        results = pool.map(process_videos_on_gpu, args_list)\n\n    # Combine results from all GPUs\n    all_results = []\n    for gpu_results in results:\n        all_results.extend(gpu_results)\n\n    # Save the results to a CSV file\n    output_csv = 'feature_extraction/content_features/content_descriptions.csv'\n    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n        fieldnames = ['video_id', 'frame_id', 'description']\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n        writer.writeheader()\n        for result in all_results:\n            writer.writerow(result)\n\n    print(f\"Content descriptions saved to {output_csv}\")\n\n    print(\"Converting descriptions into embeddings...\")\n    content_embeddings.sentence_to_embeddings()\n\n\nif __name__ == \"__main__\":\n    extract_content_features()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:18:23.060266Z","iopub.execute_input":"2025-08-20T17:18:23.060449Z","iopub.status.idle":"2025-08-20T17:18:23.069893Z","shell.execute_reply.started":"2025-08-20T17:18:23.060435Z","shell.execute_reply":"2025-08-20T17:18:23.069346Z"}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/feature_extraction/content_features/content_feature_extraction.py\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:18:23.07073Z","iopub.execute_input":"2025-08-20T17:18:23.070941Z","iopub.status.idle":"2025-08-20T17:18:23.193787Z","shell.execute_reply.started":"2025-08-20T17:18:23.07092Z","shell.execute_reply":"2025-08-20T17:18:23.192954Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:18:23.194855Z","iopub.execute_input":"2025-08-20T17:18:23.195159Z","iopub.status.idle":"2025-08-20T17:18:36.782425Z","shell.execute_reply.started":"2025-08-20T17:18:23.195134Z","shell.execute_reply":"2025-08-20T17:18:36.781518Z"}},"outputs":[{"name":"stdout","text":"Collecting DBCV@ git+https://github.com/christopherjenness/DBCV.git@db7345c45ab7d33ea500778e5c9048fd9f7d3156 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 16))\n  Cloning https://github.com/christopherjenness/DBCV.git (to revision db7345c45ab7d33ea500778e5c9048fd9f7d3156) to /tmp/pip-install-gcjvu9cr/dbcv_e05ad11278bb4a6eb7e594058f83b544\n  Running command git clone --filter=blob:none --quiet https://github.com/christopherjenness/DBCV.git /tmp/pip-install-gcjvu9cr/dbcv_e05ad11278bb4a6eb7e594058f83b544\n  Running command git rev-parse -q --verify 'sha^db7345c45ab7d33ea500778e5c9048fd9f7d3156'\n  Running command git fetch -q https://github.com/christopherjenness/DBCV.git db7345c45ab7d33ea500778e5c9048fd9f7d3156\n  Resolved https://github.com/christopherjenness/DBCV.git to commit db7345c45ab7d33ea500778e5c9048fd9f7d3156\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting accelerate==1.1.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 1))\n  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\nCollecting aiohappyeyeballs==2.4.4 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 2))\n  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\nCollecting aiohttp==3.11.11 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 3))\n  Downloading aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\nRequirement already satisfied: aiosignal==1.3.2 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 4)) (1.3.2)\nCollecting async-timeout==5.0.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 5))\n  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\nCollecting attrs==24.3.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 6))\n  Downloading attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\nCollecting bert-score==0.3.13 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 7))\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nCollecting bitsandbytes==0.44.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 8))\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nCollecting certifi==2024.8.30 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 9))\n  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\nCollecting charset-normalizer==3.4.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 10))\n  Downloading charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\nCollecting click==8.1.7 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 11))\n  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: colorama==0.4.6 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 12)) (0.4.6)\nCollecting contourpy==1.3.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 13))\n  Downloading contourpy-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\nRequirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 14)) (0.12.1)\nCollecting datasets==3.2.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 15))\n  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\nCollecting decord==0.6.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 17))\n  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\nRequirement already satisfied: dill==0.3.8 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 18)) (0.3.8)\nCollecting filelock==3.13.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 19))\n  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\nCollecting fonttools==4.55.3 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 20))\n  Downloading fonttools-4.55.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting frozenlist==1.5.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 21))\n  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nCollecting fsspec==2024.2.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 22))\n  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\nCollecting h5py==3.12.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 23))\n  Downloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nRequirement already satisfied: hdbscan==0.8.40 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 24)) (0.8.40)\nCollecting huggingface-hub==0.26.2 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 25))\n  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 26)) (3.10)\nCollecting imageio==2.36.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 27))\n  Downloading imageio-2.36.0-py3-none-any.whl.metadata (5.2 kB)\nCollecting importlib_resources==6.4.5 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 28))\n  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\nCollecting Jinja2==3.1.3 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 29))\n  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\nCollecting joblib==1.4.2 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 30))\n  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting kiwisolver==1.4.7 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 31))\n  Downloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\nRequirement already satisfied: lazy_loader==0.4 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 32)) (0.4)\nRequirement already satisfied: llvmlite==0.43.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 33)) (0.43.0)\nCollecting MarkupSafe==2.1.5 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 34))\n  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nCollecting matplotlib==3.9.4 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 35))\n  Downloading matplotlib-3.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 36)) (1.3.0)\nCollecting multidict==6.1.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 37))\n  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: multiprocess==0.70.16 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 38)) (0.70.16)\nCollecting networkx==3.2.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 39))\n  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\nRequirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 40)) (3.9.1)\nRequirement already satisfied: numba==0.60.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 41)) (0.60.0)\nCollecting numpy==2.0.2 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 42))\n  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opencv-python==4.10.0.84 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 43))\n  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nCollecting packaging==24.2 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 44))\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: pandas==2.2.3 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 45)) (2.2.3)\nCollecting peft==0.14.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 46))\n  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\nCollecting pillow==11.0.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 47))\n  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\nCollecting propcache==0.2.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 48))\n  Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\nCollecting psutil==6.1.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 49))\n  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\nCollecting pyarrow==18.1.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 50))\n  Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\nCollecting pycocoevalcap==1.2 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 51))\n  Downloading pycocoevalcap-1.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting pycocotools==2.0.8 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 52))\n  Downloading pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: pynndescent==0.5.13 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 53)) (0.5.13)\nCollecting pyparsing==3.2.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 54))\n  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 55)) (2.9.0.post0)\nCollecting pytz==2024.2 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 56))\n  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: PyYAML==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 57)) (6.0.2)\nRequirement already satisfied: regex==2024.11.6 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 58)) (2024.11.6)\nCollecting requests==2.32.3 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 59))\n  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\nCollecting safetensors==0.4.5 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 60))\n  Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting scikit-image==0.24.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 61))\n  Downloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\nCollecting scikit-learn==1.6.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 62))\n  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nCollecting scipy==1.13.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 63))\n  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sentence-transformers==3.3.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 64))\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: six==1.17.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 65)) (1.17.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 66)) (1.13.1)\nCollecting threadpoolctl==3.5.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 67))\n  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\nCollecting tifffile==2024.8.30 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 68))\n  Downloading tifffile-2024.8.30-py3-none-any.whl.metadata (31 kB)\nCollecting tokenizers==0.20.4 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 69))\n  Downloading tokenizers-0.20.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.5.1+cu118 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.5.1+cu118\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:18:36.783415Z","iopub.execute_input":"2025-08-20T17:18:36.783684Z","iopub.status.idle":"2025-08-20T17:19:53.409285Z","shell.execute_reply.started":"2025-08-20T17:18:36.783659Z","shell.execute_reply":"2025-08-20T17:19:53.408616Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed bitsandbytes-0.47.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HUNGGING_FACE\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:19:53.410274Z","iopub.execute_input":"2025-08-20T17:19:53.410521Z","iopub.status.idle":"2025-08-20T17:19:53.536358Z","shell.execute_reply.started":"2025-08-20T17:19:53.410498Z","shell.execute_reply":"2025-08-20T17:19:53.535844Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from huggingface_hub import login\n\n# Dán token vào đây\nlogin(secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:19:53.538231Z","iopub.execute_input":"2025-08-20T17:19:53.538426Z","iopub.status.idle":"2025-08-20T17:19:54.077578Z","shell.execute_reply.started":"2025-08-20T17:19:53.53841Z","shell.execute_reply":"2025-08-20T17:19:54.077046Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"!python main.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T17:19:54.07816Z","iopub.execute_input":"2025-08-20T17:19:54.078338Z"}},"outputs":[{"name":"stdout","text":"2025-08-20 17:20:06.015371: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755710406.179111     147 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755710406.228678     147 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nFeature Extraction is started...\nExtracting Color Features...\nProcessing L21_V001:   4%|▌              | 1514/37849 [02:49<1:05:42,  9.22it/s]","output_type":"stream"}],"execution_count":null}]}