{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/phamhoang1909/extract-frame?scriptVersionId=257141462\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"75884a61","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-08-20T17:25:13.989014Z","iopub.status.busy":"2025-08-20T17:25:13.988747Z","iopub.status.idle":"2025-08-20T17:25:15.226343Z","shell.execute_reply":"2025-08-20T17:25:15.225482Z"},"papermill":{"duration":1.243515,"end_time":"2025-08-20T17:25:15.228034","exception":false,"start_time":"2025-08-20T17:25:13.984519","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'tri-modal-keyframe-extraction'...\r\n","remote: Enumerating objects: 51, done.\u001b[K\r\n","remote: Counting objects: 100% (51/51), done.\u001b[K\r\n","remote: Compressing objects: 100% (46/46), done.\u001b[K\r\n","remote: Total 51 (delta 4), reused 51 (delta 4), pack-reused 0 (from 0)\u001b[K\r\n","Receiving objects: 100% (51/51), 1.41 MiB | 9.66 MiB/s, done.\r\n","Resolving deltas: 100% (4/4), done.\r\n"]}],"source":["!git clone https://github.com/hein-nkhh/tri-modal-keyframe-extraction.git"]},{"cell_type":"code","execution_count":2,"id":"689f6312","metadata":{"execution":{"iopub.execute_input":"2025-08-20T17:25:15.236222Z","iopub.status.busy":"2025-08-20T17:25:15.235631Z","iopub.status.idle":"2025-08-20T17:25:15.243356Z","shell.execute_reply":"2025-08-20T17:25:15.242677Z"},"papermill":{"duration":0.012851,"end_time":"2025-08-20T17:25:15.244557","exception":false,"start_time":"2025-08-20T17:25:15.231706","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction\n"]}],"source":["%cd /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction"]},{"cell_type":"code","execution_count":3,"id":"861d2375","metadata":{"execution":{"iopub.execute_input":"2025-08-20T17:25:15.251591Z","iopub.status.busy":"2025-08-20T17:25:15.251357Z","iopub.status.idle":"2025-08-20T17:25:15.257492Z","shell.execute_reply":"2025-08-20T17:25:15.256626Z"},"papermill":{"duration":0.011182,"end_time":"2025-08-20T17:25:15.258777","exception":false,"start_time":"2025-08-20T17:25:15.247595","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/main.py\n"]}],"source":["%%writefile /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/main.py\n","from feature_extraction.color_features import color_feature_extraction\n","from feature_extraction.image_features import image_feature_extraction\n","from feature_extraction.content_features import content_feature_extraction\n","from feature_extraction.cross_modal_features import feature_level_fusion\n","from clustering import cluster_frames\n","from frame_selection import candidate_frame_selection\n","import time\n","\n","def main():\n","\n","    start = time.time()\n","\n","    # video_folder = \"evaluation/\"\n","    # dataset_name = \"Summe\"\n","\n","    full_path = \"/kaggle/input/sample-video\"\n","\n","    print(\"Feature Extraction is started...\")\n","\n","    print(\"Extracting Color Features...\")\n","    color_feature_extraction.extract_color_features(full_path, frame_interval=1)\n","\n","    print(\"Extracting Image Features...\")\n","    image_feature_extraction.extract_image_features(full_path, frame_interval=1)\n","\n","    print(\"Extracting Content Features...\")\n","    content_feature_extraction.extract_content_features(full_path, frame_interval=1)\n","\n","    print(\"Fusing the Features...\")\n","    feature_level_fusion.fuse_features()\n","\n","    print(\"Clustering the Fused Features...\")\n","    cluster_frames.cluster(visualize=False)\n","\n","    print(\"Selecting the Candidate Keyframes...\")\n","    candidate_frame_selection.find_candidate_keyframes(full_path)\n","\n","    end = time.time()\n","    print(\"Time passed:\" + str(end-start))\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":4,"id":"5b8662fa","metadata":{"execution":{"iopub.execute_input":"2025-08-20T17:25:15.266319Z","iopub.status.busy":"2025-08-20T17:25:15.265664Z","iopub.status.idle":"2025-08-20T17:25:15.268939Z","shell.execute_reply":"2025-08-20T17:25:15.26842Z"},"papermill":{"duration":0.008018,"end_time":"2025-08-20T17:25:15.26999","exception":false,"start_time":"2025-08-20T17:25:15.261972","status":"completed"},"tags":[]},"outputs":[],"source":["# from multiprocessing import set_start_method\n","# try:\n","#     set_start_method(\"spawn\")\n","# except RuntimeError:\n","#     pass"]},{"cell_type":"code","execution_count":5,"id":"ea874ff6","metadata":{"execution":{"iopub.execute_input":"2025-08-20T17:25:15.277008Z","iopub.status.busy":"2025-08-20T17:25:15.276756Z","iopub.status.idle":"2025-08-20T17:25:15.285868Z","shell.execute_reply":"2025-08-20T17:25:15.285231Z"},"papermill":{"duration":0.014169,"end_time":"2025-08-20T17:25:15.287024","exception":false,"start_time":"2025-08-20T17:25:15.272855","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/feature_extraction/content_features/content_feature_extraction.py\n"]}],"source":["%%writefile /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/feature_extraction/content_features/content_feature_extraction.py\n","import os\n","import cv2\n","import torch\n","from PIL import Image\n","from tqdm import tqdm\n","import csv\n","from multiprocessing import Pool, set_start_method\n","from transformers import MllamaForConditionalGeneration, AutoProcessor\n","from transformers import BitsAndBytesConfig\n","from feature_extraction.content_features import content_embeddings\n","\n","\n","def get_videos(directory='../../test_videos'):\n","    \"\"\"\n","    Retrieves video file paths from the specified directory.\n","    \"\"\"\n","    video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.flv')\n","\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","        print(f\"Created directory: {directory}\")\n","\n","    video_files = []\n","    for root, dirs, files in os.walk(directory):\n","        for file in files:\n","            if file.lower().endswith(video_extensions):\n","                video_files.append(os.path.join(root, file))\n","\n","    if not video_files:\n","        print(f\"No video files found in '{directory}'. Please add videos to process.\")\n","\n","    return video_files\n","\n","\n","def  initialize_model():\n","    \"\"\"\n","    Initializes the Llama 3.2-11B-Vision-Instruct model and processor with quantization.\n","    \"\"\"\n","    model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n","\n","    config = BitsAndBytesConfig(\n","        load_in_4bit=True,\n","        bnb_4bit_quant_type=\"nf4\",\n","        bnb_4bit_use_double_quant=True,\n","        bnb_4bit_compute_dtype=torch.bfloat16,\n","    )\n","    \n","    # Set quantization configuration\n","    # quantization_config = BitsAndBytesConfig(\n","    #     load_in_4bit=True,\n","    #     bnb_4bit_quant_type='nf4',\n","    #     bnb_4bit_use_double_quant=True,\n","    #     bnb_4bit_compute_dtype=torch.bfloat16\n","    # )\n","\n","    # Load the model with quantization\n","    model = MllamaForConditionalGeneration.from_pretrained(\n","        model_id,\n","        # quantization_config=quantization_config,\n","        # low_cpu_mem_usage=True,\n","        # torch_dtype=torch.bfloat16,\n","        quantization_config=config,\n","        device_map=\"auto\"\n","    )\n","    model.eval()\n","\n","    # Compile the model for potential speed gains (requires Torch 2.0+)\n","    model = torch.compile(model, mode=\"default\")\n","\n","    # Load the processor\n","    processor = AutoProcessor.from_pretrained(model_id)\n","\n","    return model, processor, torch.device('cuda')\n","\n","\n","def generate_description(frames, model, processor, device):\n","    \"\"\"\n","    Generates content descriptions for a list of frames using the model.\n","    If the model returns a response indicating it does not see the image,\n","    we replace the description with a default placeholder.\n","    \"\"\"\n","    # Convert each frame from BGR to RGB using slicing (usually faster than cv2.cvtColor)\n","    images = [Image.fromarray(frame[..., ::-1]) for frame in frames]\n","\n","    # Since the prompt is identical for every image, compute it once:\n","    prompt = processor.apply_chat_template(\n","        [{\"role\": \"user\", \"content\": [{\"type\": \"image\"},\n","                                       {\"type\": \"text\", \"text\": \"In one sentence, describe the visible content of this provided image: \"}] }],\n","        add_generation_prompt=True\n","    )\n","    # Replicate the same prompt for each image (batch_size remains 1 for each call)\n","    input_texts = [prompt] * len(images)\n","\n","    inputs = processor(\n","        images=images,\n","        text=input_texts,\n","        add_special_tokens=False,\n","        return_tensors=\"pt\",\n","        padding=True\n","    ).to(device)\n","\n","    prompt_lengths = inputs['input_ids'].ne(processor.tokenizer.pad_token_id).sum(dim=1)\n","\n","    with torch.inference_mode():\n","        outputs = model.generate(\n","            **inputs,\n","            max_new_tokens=30,\n","            do_sample=False,  # greedy decoding\n","            temperature=None,\n","            top_p=None\n","        )\n","\n","    descriptions = []\n","    unwanted_tokens = [\"<|eot_id|>\", \"<|finetune_right_pad_id|>\"]\n","\n","    # Keywords that indicate the model did not \"see\" the image\n","    no_image_keywords = [\n","        \"have access to an image\",\n","        \"no image provided\",\n","        \"no image\",\n","        \"not seeing\",\n","        \"image is blank\",\n","        \"share the image with me\",\n","        \"see an image\",\n","        \"access images\",\n","        \"access the images\",\n","        \"unable to view or describe\",\n","        \"not able to view the image\",\n","        \"to view or access images\",\n","        \"see the image\",\n","        \"Unfortunately\",\n","    ]\n","\n","    for i, output in enumerate(outputs):\n","        prompt_length = prompt_lengths[i]\n","        response = processor.decode(output[prompt_length:], skip_special_tokens=True)\n","        # Remove unwanted tokens manually\n","        for t in unwanted_tokens:\n","            response = response.replace(t, \"\")\n","        response = response.strip()\n","\n","        if any(keyword in response.lower() for keyword in no_image_keywords):\n","            response = \"No visible content\"\n","\n","        descriptions.append(response)\n","\n","    return descriptions\n","\n","\n","def process_videos_on_gpu(args):\n","    \"\"\"\n","    Processes the assigned videos on the given GPU.\n","    Uses a background thread to prefetch frames while running inference.\n","    \"\"\"\n","    import threading\n","    from queue import Queue, Empty\n","\n","    gpu_id, video_files, frame_interval = args\n","\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n","    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n","\n","    model, processor, device = initialize_model()\n","\n","    all_results = []\n","\n","    for video_file in video_files:\n","        video_name = os.path.splitext(os.path.basename(video_file))[0]\n","        cap = cv2.VideoCapture(video_file)\n","        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","        results = []\n","\n","        pbar = tqdm(total=total_frames, desc=f\"Processing {video_name} on GPU {gpu_id}\", leave=False)\n","\n","        # Queue to hold prefetched frames (adjust maxsize as needed)\n","        frame_queue = Queue(maxsize=20)\n","        stop_event = threading.Event()\n","\n","        def read_frames():\n","            idx = 0\n","            while True:\n","                ret, frame = cap.read()\n","                if not ret:\n","                    break\n","                if idx % frame_interval == 0:\n","                    frame_queue.put((idx, frame))\n","                idx += 1\n","                # Update progress bar as each frame is read.\n","                pbar.update(1)\n","            stop_event.set()\n","\n","        reader_thread = threading.Thread(target=read_frames)\n","        reader_thread.start()\n","\n","        # Process frames as they become available.\n","        while not (stop_event.is_set() and frame_queue.empty()):\n","            try:\n","                frame_idx, frame = frame_queue.get(timeout=1)\n","            except Empty:\n","                continue\n","            try:\n","                # Process a single frame (batch size = 1)\n","                description = generate_description([frame], model, processor, device)[0]\n","                results.append({\n","                    'video_id': video_name,\n","                    'frame_id': frame_idx,\n","                    'description': description\n","                })\n","            except Exception as e:\n","                print(f\"Error processing frame {frame_idx} of {video_name} on GPU {gpu_id}: {e}\")\n","\n","        reader_thread.join()\n","        pbar.close()\n","        cap.release()\n","        all_results.extend(results)\n","\n","    del model\n","    torch.cuda.empty_cache()\n","\n","    return all_results\n","\n","\n","def extract_content_features(video_path='../../test_videos', frame_interval=10):\n","    \"\"\"\n","    Retrieves videos, processes them in parallel across available GPUs, and saves\n","    the frame descriptions to CSV. Finally, converts the descriptions to embeddings.\n","    \"\"\"\n","    # Ensure multiprocessing uses 'spawn' method\n","    set_start_method('spawn', force=True)\n","\n","    # Step 1: Get list of video files\n","    video_files = get_videos(video_path)\n","    if not video_files:\n","        return\n","\n","    # Determine the number of available GPUs\n","    num_gpus = torch.cuda.device_count()\n","\n","    if num_gpus == 0:\n","        print(\"No GPUs available. Exiting.\")\n","        return\n","\n","    # Distribute videos across GPUs\n","    video_chunks = [[] for _ in range(num_gpus)]\n","    for idx, video_file in enumerate(video_files):\n","        gpu_id = idx % num_gpus\n","        video_chunks[gpu_id].append(video_file)\n","\n","    # Prepare arguments for multiprocessing\n","    args_list = []\n","    for gpu_id in range(num_gpus):\n","        args_list.append((gpu_id, video_chunks[gpu_id], frame_interval))\n","\n","    # Use a multiprocessing Pool to process videos in parallel\n","    with Pool(processes=num_gpus) as pool:\n","        results = pool.map(process_videos_on_gpu, args_list)\n","\n","    # Combine results from all GPUs\n","    all_results = []\n","    for gpu_results in results:\n","        all_results.extend(gpu_results)\n","\n","    # Save the results to a CSV file\n","    output_csv = 'feature_extraction/content_features/content_descriptions.csv'\n","    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n","    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n","        fieldnames = ['video_id', 'frame_id', 'description']\n","        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","        writer.writeheader()\n","        for result in all_results:\n","            writer.writerow(result)\n","\n","    print(f\"Content descriptions saved to {output_csv}\")\n","\n","    print(\"Converting descriptions into embeddings...\")\n","    content_embeddings.sentence_to_embeddings()\n","\n","\n","if __name__ == \"__main__\":\n","    extract_content_features()\n","\n"]},{"cell_type":"code","execution_count":6,"id":"aa2003cc","metadata":{"execution":{"iopub.execute_input":"2025-08-20T17:25:15.29358Z","iopub.status.busy":"2025-08-20T17:25:15.293125Z","iopub.status.idle":"2025-08-20T17:25:15.40865Z","shell.execute_reply":"2025-08-20T17:25:15.407834Z"},"papermill":{"duration":0.120344,"end_time":"2025-08-20T17:25:15.410182","exception":false,"start_time":"2025-08-20T17:25:15.289838","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction\r\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":7,"id":"8c59c118","metadata":{"execution":{"iopub.execute_input":"2025-08-20T17:25:15.417768Z","iopub.status.busy":"2025-08-20T17:25:15.417515Z","iopub.status.idle":"2025-08-20T17:25:32.48526Z","shell.execute_reply":"2025-08-20T17:25:32.484301Z"},"papermill":{"duration":17.073309,"end_time":"2025-08-20T17:25:32.486819","exception":false,"start_time":"2025-08-20T17:25:15.41351","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting DBCV@ git+https://github.com/christopherjenness/DBCV.git@db7345c45ab7d33ea500778e5c9048fd9f7d3156 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 16))\r\n","  Cloning https://github.com/christopherjenness/DBCV.git (to revision db7345c45ab7d33ea500778e5c9048fd9f7d3156) to /tmp/pip-install-0sxd5isq/dbcv_a98de2698f234e379c1dda4481990ae5\r\n","  Running command git clone --filter=blob:none --quiet https://github.com/christopherjenness/DBCV.git /tmp/pip-install-0sxd5isq/dbcv_a98de2698f234e379c1dda4481990ae5\r\n","  Running command git rev-parse -q --verify 'sha^db7345c45ab7d33ea500778e5c9048fd9f7d3156'\r\n","  Running command git fetch -q https://github.com/christopherjenness/DBCV.git db7345c45ab7d33ea500778e5c9048fd9f7d3156\r\n","  Resolved https://github.com/christopherjenness/DBCV.git to commit db7345c45ab7d33ea500778e5c9048fd9f7d3156\r\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","Collecting accelerate==1.1.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 1))\r\n","  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\r\n","Collecting aiohappyeyeballs==2.4.4 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 2))\r\n","  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\r\n","Collecting aiohttp==3.11.11 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 3))\r\n","  Downloading aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\r\n","Requirement already satisfied: aiosignal==1.3.2 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 4)) (1.3.2)\r\n","Collecting async-timeout==5.0.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 5))\r\n","  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\r\n","Collecting attrs==24.3.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 6))\r\n","  Downloading attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\r\n","Collecting bert-score==0.3.13 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 7))\r\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\r\n","Collecting bitsandbytes==0.44.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 8))\r\n","  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\r\n","Collecting certifi==2024.8.30 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 9))\r\n","  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\r\n","Collecting charset-normalizer==3.4.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 10))\r\n","  Downloading charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\r\n","Collecting click==8.1.7 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 11))\r\n","  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\r\n","Requirement already satisfied: colorama==0.4.6 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 12)) (0.4.6)\r\n","Collecting contourpy==1.3.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 13))\r\n","  Downloading contourpy-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\r\n","Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 14)) (0.12.1)\r\n","Collecting datasets==3.2.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 15))\r\n","  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\r\n","Collecting decord==0.6.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 17))\r\n","  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\r\n","Requirement already satisfied: dill==0.3.8 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 18)) (0.3.8)\r\n","Collecting filelock==3.13.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 19))\r\n","  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\r\n","Collecting fonttools==4.55.3 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 20))\r\n","  Downloading fonttools-4.55.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hCollecting frozenlist==1.5.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 21))\r\n","  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\r\n","Collecting fsspec==2024.2.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 22))\r\n","  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\r\n","Collecting h5py==3.12.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 23))\r\n","  Downloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\r\n","Requirement already satisfied: hdbscan==0.8.40 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 24)) (0.8.40)\r\n","Collecting huggingface-hub==0.26.2 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 25))\r\n","  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\r\n","Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 26)) (3.10)\r\n","Collecting imageio==2.36.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 27))\r\n","  Downloading imageio-2.36.0-py3-none-any.whl.metadata (5.2 kB)\r\n","Collecting importlib_resources==6.4.5 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 28))\r\n","  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\r\n","Collecting Jinja2==3.1.3 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 29))\r\n","  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\r\n","Collecting joblib==1.4.2 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 30))\r\n","  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\r\n","Collecting kiwisolver==1.4.7 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 31))\r\n","  Downloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\r\n","Requirement already satisfied: lazy_loader==0.4 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 32)) (0.4)\r\n","Requirement already satisfied: llvmlite==0.43.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 33)) (0.43.0)\r\n","Collecting MarkupSafe==2.1.5 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 34))\r\n","  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\r\n","Collecting matplotlib==3.9.4 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 35))\r\n","  Downloading matplotlib-3.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n","Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 36)) (1.3.0)\r\n","Collecting multidict==6.1.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 37))\r\n","  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\r\n","Requirement already satisfied: multiprocess==0.70.16 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 38)) (0.70.16)\r\n","Collecting networkx==3.2.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 39))\r\n","  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\r\n","Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 40)) (3.9.1)\r\n","Requirement already satisfied: numba==0.60.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 41)) (0.60.0)\r\n","Collecting numpy==2.0.2 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 42))\r\n","  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hCollecting opencv-python==4.10.0.84 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 43))\r\n","  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\r\n","Collecting packaging==24.2 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 44))\r\n","  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\r\n","Requirement already satisfied: pandas==2.2.3 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 45)) (2.2.3)\r\n","Collecting peft==0.14.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 46))\r\n","  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\r\n","Collecting pillow==11.0.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 47))\r\n","  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\r\n","Collecting propcache==0.2.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 48))\r\n","  Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\r\n","Collecting psutil==6.1.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 49))\r\n","  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\r\n","Collecting pyarrow==18.1.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 50))\r\n","  Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\r\n","Collecting pycocoevalcap==1.2 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 51))\r\n","  Downloading pycocoevalcap-1.2-py3-none-any.whl.metadata (3.2 kB)\r\n","Collecting pycocotools==2.0.8 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 52))\r\n","  Downloading pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\n","Requirement already satisfied: pynndescent==0.5.13 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 53)) (0.5.13)\r\n","Collecting pyparsing==3.2.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 54))\r\n","  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\r\n","Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 55)) (2.9.0.post0)\r\n","Collecting pytz==2024.2 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 56))\r\n","  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\r\n","Requirement already satisfied: PyYAML==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 57)) (6.0.2)\r\n","Requirement already satisfied: regex==2024.11.6 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 58)) (2024.11.6)\r\n","Collecting requests==2.32.3 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 59))\r\n","  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\r\n","Collecting safetensors==0.4.5 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 60))\r\n","  Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\n","Collecting scikit-image==0.24.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 61))\r\n","  Downloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\r\n","Collecting scikit-learn==1.6.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 62))\r\n","  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\n","Collecting scipy==1.13.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 63))\r\n","  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hCollecting sentence-transformers==3.3.1 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 64))\r\n","  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\r\n","Requirement already satisfied: six==1.17.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 65)) (1.17.0)\r\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 66)) (1.13.1)\r\n","Collecting threadpoolctl==3.5.0 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 67))\r\n","  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\r\n","Collecting tifffile==2024.8.30 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 68))\r\n","  Downloading tifffile-2024.8.30-py3-none-any.whl.metadata (31 kB)\r\n","Collecting tokenizers==0.20.4 (from -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt (line 69))\r\n","  Downloading tokenizers-0.20.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n","\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11\u001b[0m\u001b[31m\r\n","\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.5.1+cu118 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0)\u001b[0m\u001b[31m\r\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.5.1+cu118\u001b[0m\u001b[31m\r\n","\u001b[0m"]}],"source":["!pip install -r /kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/requirements.txt"]},{"cell_type":"code","execution_count":8,"id":"25d54c80","metadata":{"execution":{"iopub.execute_input":"2025-08-20T17:25:32.500319Z","iopub.status.busy":"2025-08-20T17:25:32.500039Z","iopub.status.idle":"2025-08-20T17:26:57.027461Z","shell.execute_reply":"2025-08-20T17:26:57.026619Z"},"papermill":{"duration":84.535665,"end_time":"2025-08-20T17:26:57.029052","exception":false,"start_time":"2025-08-20T17:25:32.493387","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting bitsandbytes\r\n","  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\r\n","Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\r\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\r\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\r\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\r\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\r\n","Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.2.0)\r\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.2.0)\r\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\r\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\r\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\r\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\r\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\r\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.5.1)\r\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\r\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\r\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\r\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\r\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\r\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\r\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\r\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\r\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\r\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\r\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\r\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\r\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\r\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\r\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\r\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\r\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\r\n","Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\r\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.2.0)\r\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\r\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\r\n","Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\r\n","  Attempting uninstall: nvidia-nvjitlink-cu12\r\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-curand-cu12\r\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n","  Attempting uninstall: nvidia-cufft-cu12\r\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cublas-cu12\r\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n","  Attempting uninstall: nvidia-cusparse-cu12\r\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n","  Attempting uninstall: nvidia-cudnn-cu12\r\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n","  Attempting uninstall: nvidia-cusolver-cu12\r\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n","Successfully installed bitsandbytes-0.47.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\r\n"]}],"source":["!pip install -U bitsandbytes"]},{"cell_type":"code","execution_count":9,"id":"f5702a69","metadata":{"execution":{"iopub.execute_input":"2025-08-20T17:26:57.081651Z","iopub.status.busy":"2025-08-20T17:26:57.081374Z","iopub.status.idle":"2025-08-20T17:26:57.204179Z","shell.execute_reply":"2025-08-20T17:26:57.203384Z"},"papermill":{"duration":0.150988,"end_time":"2025-08-20T17:26:57.205819","exception":false,"start_time":"2025-08-20T17:26:57.054831","status":"completed"},"tags":[]},"outputs":[],"source":["from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","secret_value_0 = user_secrets.get_secret(\"HUNGGING_FACE\")"]},{"cell_type":"code","execution_count":10,"id":"29a86d63","metadata":{"execution":{"iopub.execute_input":"2025-08-20T17:26:57.258488Z","iopub.status.busy":"2025-08-20T17:26:57.258179Z","iopub.status.idle":"2025-08-20T17:26:57.977643Z","shell.execute_reply":"2025-08-20T17:26:57.976816Z"},"papermill":{"duration":0.747086,"end_time":"2025-08-20T17:26:57.979072","exception":false,"start_time":"2025-08-20T17:26:57.231986","status":"completed"},"tags":[]},"outputs":[],"source":["from huggingface_hub import login\n","\n","# Dán token vào đây\n","login(secret_value_0)"]},{"cell_type":"code","execution_count":11,"id":"e6414a6a","metadata":{"execution":{"iopub.execute_input":"2025-08-20T17:26:58.030521Z","iopub.status.busy":"2025-08-20T17:26:58.030235Z","iopub.status.idle":"2025-08-20T18:56:43.89309Z","shell.execute_reply":"2025-08-20T18:56:43.892323Z"},"papermill":{"duration":5385.889303,"end_time":"2025-08-20T18:56:43.894522","exception":false,"start_time":"2025-08-20T17:26:58.005219","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-08-20 17:27:22.813888: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n","E0000 00:00:1755710843.164700     108 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n","E0000 00:00:1755710843.263019     108 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n","Feature Extraction is started...\r\n","Extracting Color Features...\r\n","Processing Videos: 100%|██████████████████████| 1/1 [1:28:40<00:00, 5320.33s/it]\r\n","Features dictionary saved to feature_extraction/color_features/color_features_dict.h5\r\n","Extracting Image Features...\r\n","multiprocessing.pool.RemoteTraceback: \r\n","\"\"\"\r\n","Traceback (most recent call last):\r\n","  File \"/usr/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\r\n","    result = (True, func(*args, **kwds))\r\n","                    ^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/lib/python3.11/multiprocessing/pool.py\", line 51, in starmapstar\r\n","    return list(itertools.starmap(args[0], args[1]))\r\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/feature_extraction/image_features/image_feature_extraction.py\", line 196, in process_videos_on_gpu\r\n","    torch.cuda.set_device(gpu_id)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\", line 476, in set_device\r\n","    torch._C._cuda_setDevice(device)\r\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\", line 305, in _lazy_init\r\n","    raise RuntimeError(\r\n","RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\r\n","\"\"\"\r\n","\r\n","The above exception was the direct cause of the following exception:\r\n","\r\n","Traceback (most recent call last):\r\n","  File \"/kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/main.py\", line 41, in <module>\r\n","    main()\r\n","  File \"/kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/main.py\", line 24, in main\r\n","    image_feature_extraction.extract_image_features(full_path, frame_interval=1)\r\n","  File \"/kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/feature_extraction/image_features/image_feature_extraction.py\", line 247, in extract_image_features\r\n","    results = pool.starmap(process_videos_on_gpu, args)\r\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/lib/python3.11/multiprocessing/pool.py\", line 375, in starmap\r\n","    return self._map_async(func, iterable, starmapstar, chunksize).get()\r\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/lib/python3.11/multiprocessing/pool.py\", line 774, in get\r\n","    raise self._value\r\n","  File \"/usr/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\r\n","    result = (True, func(*args, **kwds))\r\n","^^^^^^^^^^^^^^^\r\n","  File \"/usr/lib/python3.11/multiprocessing/pool.py\", line 51, in starmapstar\r\n","    return list(itertools.starmap(args[0], args[1]))\r\n","      ^^^^^^^^^^^^^^^^^\r\n","  File \"/kaggle/working/tri-modal-keyframe-extraction/Keyframe_Extraction/feature_extraction/image_features/image_feature_extraction.py\", line 196, in process_videos_on_gpu\r\n","    torch.cuda.set_device(gpu_id)\r\n","      ^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\", line 476, in set_device\r\n","    torch._C._cuda_setDevice(device)\r\n","  ^^^^^^^^^^^^^^^^^\r\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\", line 305, in _lazy_init\r\n","    raise RuntimeError(\r\n","^^^^^^^^^^^^^^^\r\n","RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\r\n","\u001b[0m"]}],"source":["!python main.py"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":8099076,"sourceId":12808614,"sourceType":"datasetVersion"},{"datasetId":8102851,"sourceId":12814286,"sourceType":"datasetVersion"}],"dockerImageVersionId":31089,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":5496.330417,"end_time":"2025-08-20T18:56:44.308562","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-08-20T17:25:07.978145","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}