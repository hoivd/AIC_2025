{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cài đặt thư viện","metadata":{}},{"cell_type":"code","source":"!pip install open-clip-torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:16:16.045256Z","iopub.execute_input":"2025-08-23T09:16:16.045877Z","iopub.status.idle":"2025-08-23T09:17:50.418701Z","shell.execute_reply.started":"2025-08-23T09:16:16.045847Z","shell.execute_reply":"2025-08-23T09:17:50.417402Z"}},"outputs":[{"name":"stdout","text":"Collecting open-clip-torch\n  Downloading open_clip_torch-3.1.0-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.21.0+cu124)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (2024.11.6)\nCollecting ftfy (from open-clip-torch)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (4.67.1)\nRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.33.1)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.5.3)\nCollecting timm>=1.0.17 (from open-clip-torch)\n  Downloading timm-1.0.19-py3-none-any.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm>=1.0.17->open-clip-torch) (6.0.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open-clip-torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open-clip-torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open-clip-torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open-clip-torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open-clip-torch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->open-clip-torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->open-clip-torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->open-clip-torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->open-clip-torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->open-clip-torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->open-clip-torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->open-clip-torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->open-clip-torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->open-clip-torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open-clip-torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open-clip-torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open-clip-torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->open-clip-torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open-clip-torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open-clip-torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->open-clip-torch) (1.3.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open-clip-torch) (0.2.13)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (2.32.4)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (1.1.5)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->open-clip-torch) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->open-clip-torch) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->open-clip-torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open-clip-torch) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open-clip-torch) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open-clip-torch) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open-clip-torch) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open-clip-torch) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open-clip-torch) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->open-clip-torch) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->open-clip-torch) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->open-clip-torch) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->open-clip-torch) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->open-clip-torch) (2024.2.0)\nDownloading open_clip_torch-3.1.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading timm-1.0.19-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm, open-clip-torch\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.15\n    Uninstalling timm-1.0.15:\n      Successfully uninstalled timm-1.0.15\nSuccessfully installed ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 open-clip-torch-3.1.0 timm-1.0.19\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Import thư viện","metadata":{}},{"cell_type":"code","source":"# # -*- coding: utf-8 -*-\nimport os, cv2, torch, numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom IPython.display import display\nimport pickle\nimport numpy as np","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hàm embedd","metadata":{}},{"cell_type":"code","source":"# ======= CHỌN BACKEND =======\n# \"openclip\" (như bạn đang dùng) hoặc \"siglip2\"\nBACKEND = os.environ.get(\"MM_BACKEND\", \"openclip\")  # \"openclip\" | \"siglip2\"\n\n# ======= LOAD MODEL =======\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nif BACKEND == \"openclip\":\n    import open_clip\n    OC_MODEL = \"ViT-g-14\"\n    OC_PRETRAINED = \"laion2b_s34b_b88k\"\n    model, _, preprocess = open_clip.create_model_and_transforms(\n        OC_MODEL, pretrained=OC_PRETRAINED, device=DEVICE\n    )\n    tokenizer = open_clip.get_tokenizer(OC_MODEL)\n    model.eval()\n\nelif BACKEND == \"siglip2\":\n    # pip install -U transformers accelerate bitsandbytes\n    from transformers import AutoProcessor, AutoModel\n    CKPT = os.environ.get(\"SIGLIP2_CKPT\", \"google/siglip2-giant-opt-patch16-384\")\n    processor = AutoProcessor.from_pretrained(CKPT)\n    model = AutoModel.from_pretrained(CKPT, device_map=\"auto\").eval()\nelse:\n    raise ValueError(\"BACKEND phải là 'openclip' hoặc 'siglip2'.\")\n\ndef extract_frames_with_opencv(video_path: str, target_height: int = 27, target_width: int = 48, show_progressbar: bool = False):\n    \"\"\"\n    Extracts frames from a video using OpenCV with optional CUDA support and progress tracking.\n    \"\"\"\n    logger.info(f\"Opening video: {video_path}\")\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        logger.error(f\"Failed to open video: {video_path}\")\n        raise ValueError(f\"Failed to open video: {video_path}\")\n\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    frames = []\n\n    # Initialize progress bar\n    progress_bar = tqdm(total=total_frames, desc=\"Extracting frames\", unit=\"frame\") if show_progressbar else None\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        # Convert frame to RGB\n        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        # Resize frame\n        frame_resized = cv2.resize(frame_rgb, (target_width, target_height))\n        frames.append(frame_resized)\n        if progress_bar:\n            progress_bar.update(1)\n\n    cap.release()\n    if progress_bar:\n        progress_bar.close()\n    logger.info(f\"Extracted {len(frames)} frames\")\n    return np.array(frames)\n\n# ======= VIDEO FRAME SAMPLER =======\ndef sample_frames(video_path, every_ms=500, max_frames=None,\n                  time_window=\"first_half\", start_sec=None, end_sec=None):\n    \"\"\"\n    time_window: \"first_half\" | \"second_half\" | None\n    Hoặc chỉ định start_sec/end_sec (ưu tiên hơn time_window).\n    \"\"\"\n    cap = cv2.VideoCapture(video_path)\n    assert cap.isOpened(), f\"Không mở được video: {video_path}\"\n    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n    n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n    dur = (n_frames / fps) if n_frames > 0 else None\n\n    # Tính khoảng đọc\n    if start_sec is None and end_sec is None and dur is not None:\n        if time_window == \"first_half\":\n            start_sec, end_sec = 0.0, dur * 0.5\n        elif time_window == \"second_half\":\n            start_sec, end_sec = dur * 0.5, dur\n        else:\n            start_sec, end_sec = 0.0, dur  # toàn bộ\n    elif start_sec is None and end_sec is None:\n        start_sec, end_sec = 0.0, float(\"inf\")\n\n    # Seek tới frame bắt đầu (nếu biết)\n    if dur is not None:\n        start_frame = int(start_sec * fps)\n        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n\n    step = max(1, int(fps * (every_ms / 1000.0)))\n    frames, times = [], []\n    i = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n\n    with tqdm(desc=\"Đọc video (giới hạn)\", unit=\"f\") as pbar:\n        while True:\n            # Kiểm tra dừng theo end_sec (nếu POS_MSEC khả dụng)\n            pos_msec = cap.get(cv2.CAP_PROP_POS_MSEC)\n            if pos_msec > 0:\n                cur_sec = pos_msec / 1000.0\n                if cur_sec > end_sec:\n                    break\n\n            ret, fr = cap.read()\n            if not ret:\n                break\n\n            if i % step == 0:\n                rgb = cv2.cvtColor(fr, cv2.COLOR_BGR2RGB)\n                frames.append(rgb)\n\n                # Lấy thời gian hiện tại sau khi read; fallback nếu =0\n                pos_msec2 = cap.get(cv2.CAP_PROP_POS_MSEC)\n                if pos_msec2 and pos_msec2 > 0:\n                    t_sec = pos_msec2 / 1000.0\n                else:\n                    # Fallback: ước lượng theo frame index\n                    t_sec = i / fps\n                times.append(t_sec)\n\n                if max_frames and len(frames) >= max_frames:\n                    break\n\n            i += 1\n            pbar.update(1)\n\n    cap.release()\n    return frames, times\n\n# ======= EMBEDDING FUNCS (tuỳ BACKEND) =======\n@torch.no_grad()\ndef embed_images(frames, batch_size=64):\n    \"\"\"\n    frames: list[np.ndarray(H,W,3) in RGB]\n    return: np.ndarray [N, D] đã L2-norm\n    \"\"\"\n    vecs = []\n    total = len(frames)\n\n    if BACKEND == \"openclip\":\n        for i in tqdm(range(0, total, batch_size), desc=\"Embedding (OpenCLIP)\", unit=\"batch\"):\n            batch = [preprocess(Image.fromarray(x)) for x in frames[i:i+batch_size]]\n            batch = torch.stack(batch).to(DEVICE)\n            feats = model.encode_image(batch)\n            feats = feats / feats.norm(dim=-1, keepdim=True)\n            vecs.append(feats.float().cpu().numpy())\n\n    elif BACKEND == \"siglip2\":\n        from PIL import Image as _Image\n        pil_frames = [_Image.fromarray(x) for x in frames]\n        for i in tqdm(range(0, total, batch_size), desc=\"Embedding (SigLIP2)\", unit=\"batch\"):\n            batch = pil_frames[i:i+batch_size]\n            inputs = processor(images=batch, return_tensors=\"pt\").to(model.device)\n            img_feats = model.get_image_features(**inputs)  # (B, D)\n            img_feats = img_feats / img_feats.norm(dim=-1, keepdim=True)\n            vecs.append(img_feats.float().cpu().numpy())\n\n    return np.vstack(vecs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hàm thực thi ","metadata":{}},{"cell_type":"code","source":"# ======= DEMO (tuỳ chọn) =======\nif __name__ == \"__main__\":\n    video_path = \"/kaggle/input/keyframes-sample/L21_V001 (online-video-cutter.com).mp4\"\n\n    frames = extract_frames_with_opencv(video_path, show_progressbar=True)\n    embeddings = embed_images(frames)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Lưu embedding","metadata":{}},{"cell_type":"code","source":"with open(\"/kaggle/working/video_features.pkl\", \"wb\") as f:\n    pickle.dump(embeddings, f)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}