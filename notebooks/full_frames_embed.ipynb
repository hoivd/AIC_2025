{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12779183,"sourceType":"datasetVersion","datasetId":8079103},{"sourceId":12858514,"sourceType":"datasetVersion","datasetId":8129235},{"sourceId":12858811,"sourceType":"datasetVersion","datasetId":8133250},{"sourceId":545126,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":418001,"modelId":435667}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Clone Source Code","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/hein-nkhh/unilm.git\n%cd unilm/beit3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:28:44.426216Z","iopub.execute_input":"2025-09-05T10:28:44.426856Z","iopub.status.idle":"2025-09-05T10:28:48.633900Z","shell.execute_reply.started":"2025-09-05T10:28:44.426823Z","shell.execute_reply":"2025-09-05T10:28:48.633056Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'unilm'...\nremote: Enumerating objects: 11122, done.\u001b[K\nremote: Counting objects: 100% (43/43), done.\u001b[K\nremote: Compressing objects: 100% (25/25), done.\u001b[K\nremote: Total 11122 (delta 31), reused 18 (delta 18), pack-reused 11079 (from 4)\u001b[K\nReceiving objects: 100% (11122/11122), 75.39 MiB | 35.87 MiB/s, done.\nResolving deltas: 100% (5248/5248), done.\n/kaggle/working/unilm/beit3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Import th∆∞ vi·ªán","metadata":{}},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:28:48.635603Z","iopub.execute_input":"2025-09-05T10:28:48.635832Z","iopub.status.idle":"2025-09-05T10:30:27.192991Z","shell.execute_reply.started":"2025-09-05T10:28:48.635811Z","shell.execute_reply":"2025-09-05T10:30:27.192305Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.21.0+cu124)\nCollecting timm==0.4.12 (from -r requirements.txt (line 3))\n  Downloading timm-0.4.12-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (11.2.1)\nRequirement already satisfied: blobfile in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.0.0)\nCollecting mypy (from -r requirements.txt (line 6))\n  Downloading mypy-1.17.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.2 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\nRequirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (8.3.5)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.32.4)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.8.1)\nCollecting tensorboardX (from -r requirements.txt (line 11))\n  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.15.3)\nCollecting ftfy (from -r requirements.txt (line 13))\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (4.11.0.86)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.2.0)\nRequirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (19.0.1)\nCollecting torchmetrics==0.7.3 (from -r requirements.txt (line 17))\n  Downloading torchmetrics-0.7.3-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (4.52.4)\nCollecting deepspeed==0.4.0 (from -r requirements.txt (line 19))\n  Downloading deepspeed-0.4.0.tar.gz (444 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m444.6/444.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (2.0.10)\nCollecting pycocoevalcap (from -r requirements.txt (line 21))\n  Downloading pycocoevalcap-1.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting torchscale==0.2.0 (from -r requirements.txt (line 22))\n  Downloading torchscale-0.2.0.tar.gz (44 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting pyDeprecate==0.3.* (from torchmetrics==0.7.3->-r requirements.txt (line 17))\n  Downloading pyDeprecate-0.3.2-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchmetrics==0.7.3->-r requirements.txt (line 17)) (25.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.4.0->-r requirements.txt (line 19)) (4.67.1)\nCollecting tensorboardX (from -r requirements.txt (line 11))\n  Downloading tensorboardX-1.8-py2.py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.4.0->-r requirements.txt (line 19)) (1.11.1.4)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.4.0->-r requirements.txt (line 19)) (7.0.0)\nRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 11)) (3.20.3)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 11)) (1.17.0)\nCollecting fairscale==0.4.0 (from torchscale==0.2.0->-r requirements.txt (line 22))\n  Downloading fairscale-0.4.0.tar.gz (190 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.11/dist-packages (from blobfile->-r requirements.txt (line 5)) (3.23.0)\nRequirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile->-r requirements.txt (line 5)) (2.5.0)\nRequirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile->-r requirements.txt (line 5)) (5.4.0)\nRequirement already satisfied: mypy_extensions>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from mypy->-r requirements.txt (line 6)) (1.1.0)\nCollecting pathspec>=0.9.0 (from mypy->-r requirements.txt (line 6))\n  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 7)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 7)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 7)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 7)) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 7)) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 7)) (2.4.1)\nRequirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->-r requirements.txt (line 8)) (2.1.0)\nRequirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->-r requirements.txt (line 8)) (1.6.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 9)) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 9)) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 9)) (2025.6.15)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->-r requirements.txt (line 13)) (0.2.13)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 18)) (0.33.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 18)) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 18)) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 18)) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 18)) (0.5.3)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->-r requirements.txt (line 18)) (1.1.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 7)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 7)) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->-r requirements.txt (line 7)) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->-r requirements.txt (line 7)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->-r requirements.txt (line 7)) (2024.2.0)\nDownloading timm-0.4.12-py3-none-any.whl (376 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m398.2/398.2 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboardX-1.8-py2.py3-none-any.whl (216 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m216.3/216.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mypy-1.17.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (12.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\nBuilding wheels for collected packages: deepspeed, torchscale, fairscale\n  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for deepspeed: filename=deepspeed-0.4.0-py3-none-any.whl size=447148 sha256=9109332809f792617595fa7fab87430cfe2877838bae1a7e46971aded334302d\n  Stored in directory: /root/.cache/pip/wheels/2d/6c/59/e857be62a098db02f6b10d035ce825b949319643b75fcbbf03\n  Building wheel for torchscale (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for torchscale: filename=torchscale-0.2.0-py3-none-any.whl size=59731 sha256=99b51bd7e27c79ed02fde5d81a7ede3e7d874a7595b86d7a7e624d39dbe9fb32\n  Stored in directory: /root/.cache/pip/wheels/e4/a9/44/64be4b42608e466d86c5643f325670dc0761b698b9e847c0d2\n  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for fairscale: filename=fairscale-0.4.0-py3-none-any.whl size=240019 sha256=2cf40c1e89e069c2a94f897dcd1139970f54713f0da74b539b6a25e9a8d14068\n  Stored in directory: /root/.cache/pip/wheels/64/0d/d8/80dd4e467a3870f694ad9399e7ac0fcdc8ab78d828501a3193\nSuccessfully built deepspeed torchscale fairscale\nInstalling collected packages: pyDeprecate, pathspec, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, mypy, nvidia-cusolver-cu12, fairscale, timm, tensorboardX, torchscale, torchmetrics, pycocoevalcap, deepspeed\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.15\n    Uninstalling timm-1.0.15:\n      Successfully uninstalled timm-1.0.15\n  Attempting uninstall: torchmetrics\n    Found existing installation: torchmetrics 1.7.3\n    Uninstalling torchmetrics-1.7.3:\n      Successfully uninstalled torchmetrics-1.7.3\nSuccessfully installed deepspeed-0.4.0 fairscale-0.4.0 ftfy-6.3.1 mypy-1.17.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pathspec-0.12.1 pyDeprecate-0.3.2 pycocoevalcap-1.2 tensorboardX-1.8 timm-0.4.12 torchmetrics-0.7.3 torchscale-0.2.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\nimport time\nimport pickle\nimport torch\nfrom IPython.display import clear_output\nimport os\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer\nfrom modeling_finetune import beit3_large_patch16_384_retrieval\nfrom PIL import Image\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom torch.cuda.amp import autocast\nfrom transformers import XLMRobertaTokenizer\nimport json\nimport cv2\nfrom huggingface_hub import HfApi\nimport math\nimport torch.multiprocessing as mp\nfrom torch.utils.data import Dataset, DataLoader\nimport os\nimport time\nimport json\nimport cv2\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    XLMRobertaTokenizer\n)\nfrom modeling_finetune import beit3_large_patch16_384_retrieval\nfrom PIL import Image\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm, notebook\nimport shutil\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:27.194319Z","iopub.execute_input":"2025-09-05T10:30:27.194525Z","iopub.status.idle":"2025-09-05T10:30:38.881565Z","shell.execute_reply.started":"2025-09-05T10:30:27.194504Z","shell.execute_reply":"2025-09-05T10:30:38.880740Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import logging\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n    force=True,                 # √©p ghi ƒë√® c·∫•u h√¨nh c≈© (r·∫•t quan tr·ªçng trong notebook)\n)\n\nlogger = logging.getLogger(\"Embedd Frame\")\nlogger.info(\"Xin ch√†o\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:38.883122Z","iopub.execute_input":"2025-09-05T10:30:38.883513Z","iopub.status.idle":"2025-09-05T10:30:38.888670Z","shell.execute_reply.started":"2025-09-05T10:30:38.883492Z","shell.execute_reply":"2025-09-05T10:30:38.888127Z"}},"outputs":[{"name":"stderr","text":"2025-09-05 10:30:38,885 - Embedd Frame - INFO - Xin ch√†o\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# C√†i ƒë·∫∑t Device Torch","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:38.889485Z","iopub.execute_input":"2025-09-05T10:30:38.889783Z","iopub.status.idle":"2025-09-05T10:30:38.951235Z","shell.execute_reply.started":"2025-09-05T10:30:38.889766Z","shell.execute_reply":"2025-09-05T10:30:38.950543Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Extract Embedding","metadata":{}},{"cell_type":"code","source":"%%writefile multi_gpu_extract.py\nimport os\nimport av\nimport time\nimport json\nimport cv2\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    XLMRobertaTokenizer\n)\nfrom modeling_finetune import beit3_large_patch16_384_retrieval\nfrom PIL import Image\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm, notebook\nimport shutil\nfrom embedding_io import EmbeddingIO\nfrom hf_uploader import HFUploader\n\n# class VideoFrameDataset(Dataset):\n#     def __init__(self, video_path, save_dir=\"frames\", transform=None, show_progress=True):\n#         \"\"\"\n#         Dataset cho m·ªôt video duy nh·∫•t, preload to√†n b·ªô frame ra ·∫£nh v√† tr·∫£ v·ªÅ path.\n\n#         Args:\n#             video_path (str): ƒë∆∞·ªùng d·∫´n ƒë·∫øn file video\n#             save_dir (str): th∆∞ m·ª•c l∆∞u frame\n#             transform: torchvision transforms √°p d·ª•ng khi load frame\n#             show_progress (bool): c√≥ hi·ªÉn th·ªã tqdm progress bar hay kh√¥ng\n#         \"\"\"\n#         self.video_path = video_path\n#         self.save_dir = save_dir\n#         self.transform = transform\n#         self.frame_paths = []\n\n#         os.makedirs(self.save_dir, exist_ok=True)\n\n#         cap = cv2.VideoCapture(self.video_path)\n#         if not cap.isOpened():\n#             raise ValueError(f\"‚ö†Ô∏è Error loading video: {self.video_path}\")\n\n#         total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # t·ªïng s·ªë frame\n#         pbar = tqdm(total=total_frames, desc=f\"Extracting {video_path}\", disable=not show_progress)\n\n#         idx = 0\n#         while True:\n#             ret, frame = cap.read()\n#             if not ret:\n#                 break\n#             frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n#             # path l∆∞u frame\n#             frame_path = os.path.join(self.save_dir, f\"frame_{idx:06d}.jpg\")\n#             cv2.imwrite(frame_path, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))  # l∆∞u l·∫°i d∆∞·ªõi d·∫°ng jpg\n#             self.frame_paths.append(frame_path)\n\n#             idx += 1\n#             if idx == 2:\n#                 break\n#             pbar.update(1)\n\n#         cap.release()\n#         pbar.close()\n\n\n#         if len(self.frame_paths) == 0:\n#             raise ValueError(f\"‚ö†Ô∏è No frames extracted from video: {self.video_path}\")\n\n#     def __len__(self):\n#         return len(self.frame_paths)\n\n#     def __getitem__(self, idx):\n#         frame_path = self.frame_paths[idx]\n\n#         if self.transform:\n#             import PIL.Image\n#             img = PIL.Image.open(frame_path).convert(\"RGB\")\n#             img = self.transform(img)\n#             return img, frame_path\n\n#         return frame_path\n\nimport os\nfrom torch.utils.data import Dataset\nfrom tqdm import tqdm\nimport av\nfrom PIL import Image\n\nclass VideoFrameDataset(Dataset):\n    def __init__(self, video_path, save_dir=\"frames\", transform=None, show_progress=True):\n        \"\"\"\n        Dataset cho m·ªôt video duy nh·∫•t, preload to√†n b·ªô frame ra ·∫£nh v√† tr·∫£ v·ªÅ path.\n\n        Args:\n            video_path (str): ƒë∆∞·ªùng d·∫´n ƒë·∫øn file video\n            save_dir (str): th∆∞ m·ª•c l∆∞u frame\n            transform: torchvision transforms √°p d·ª•ng khi load frame\n            show_progress (bool): c√≥ hi·ªÉn th·ªã tqdm progress bar hay kh√¥ng\n        \"\"\"\n        self.video_path = video_path\n        self.save_dir = save_dir\n        self.transform = transform\n        self.frame_paths = []\n\n        os.makedirs(self.save_dir, exist_ok=True)\n\n        try:\n            container = av.open(self.video_path)\n        except av.AVError as e:\n            raise ValueError(f\"‚ö†Ô∏è Error loading video: {self.video_path}\\n{e}\")\n\n        total_frames = container.streams.video[0].frames\n        pbar = tqdm(total=total_frames, desc=f\"Extracting {video_path}\", disable=not show_progress)\n\n        idx = 0\n        for frame in container.decode(video=0):\n            img = frame.to_image()  # PIL Image\n            frame_path = os.path.join(self.save_dir, f\"frame_{idx:06d}.jpg\")\n            img.save(frame_path)\n            self.frame_paths.append(frame_path)\n            idx += 1\n            if idx == 10:\n                break\n            pbar.update(1)\n\n        pbar.close()\n\n        if len(self.frame_paths) == 0:\n            raise ValueError(f\"‚ö†Ô∏è No frames extracted from video: {self.video_path}\")\n\n    def __len__(self):\n        return len(self.frame_paths)\n\n    def __getitem__(self, idx):\n        frame_path = self.frame_paths[idx]\n\n        if self.transform:\n            img = Image.open(frame_path).convert(\"RGB\")\n            img = self.transform(img)\n            return img, frame_path\n\n        return frame_path\n\ndef collate_fn(batch):\n    \"\"\"B·ªè qua sample l·ªói (None)\"\"\"\n    batch = [x for x in batch if x[0] is not None]\n    if not batch:\n        return None, None\n    images, paths = zip(*batch)\n    return torch.stack(images, dim=0), list(paths)\n\ndef extract_embeddings_dataloader(dataset, model, transform, device, batch_size=64, num_workers=4):\n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        collate_fn=collate_fn,\n        prefetch_factor=3,\n        pin_memory=True\n    )\n\n    embeddings = []\n    ids = []\n\n    model.eval()\n    start_extract_embedding = time.time()\n\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"üîÑ Extracting embeddings (DataLoader)\"):\n            batch_tensor, batch_ids = batch\n            if batch_tensor is None:\n                continue\n\n            batch_tensor = batch_tensor.to(device, non_blocking=True)\n\n            with autocast():\n                vision_cls_batch = model(image=batch_tensor, only_infer=True)[0]  # (B, D)\n                vision_norm_batch = F.normalize(vision_cls_batch, p=2, dim=-1)\n\n            embeddings.extend([emb.cpu() for emb in vision_norm_batch])\n            ids.extend(batch_ids)\n\n            del batch_tensor, vision_cls_batch, vision_norm_batch\n            torch.cuda.empty_cache()\n\n    image_embeddings = torch.stack(embeddings, dim=0)\n    end_extract_embedding = time.time()\n    print(f\"Th·ªùi gian extract embedding: {end_extract_embedding-start_extract_embedding}\")\n\n    return image_embeddings, ids\n\ndef upload_embeddings(local_file: str, repo_id: str, token: str,\n                       repo_type: str = \"dataset\", path_in_repo: str = None):\n    \"\"\"\n    Upload m·ªôt file t·ª´ local l√™n Hugging Face repo v√† tr·∫£ v·ªÅ URL trong repo.\n    Args:\n        local_file: ƒë∆∞·ªùng d·∫´n file ·ªü local\n        repo_id: repo_id tr√™n Hugging Face (vd: \"username/my-dataset\")\n        token: Hugging Face token\n        repo_type: lo·∫°i repo (\"model\", \"dataset\", \"space\")\n        path_in_repo: ƒë∆∞·ªùng d·∫´n l∆∞u trong repo (m·∫∑c ƒë·ªãnh = t√™n file)\n    \"\"\"\n    uploader = HFUploader(token=token)\n    uploader.upload_file(\n        local_path=local_file,\n        repo_id=repo_id,\n        repo_type=repo_type,\n        path_in_repo=path_in_repo\n    )\n\n    if path_in_repo is None:\n        import os\n        path_in_repo = os.path.basename(local_file)\n\n    # URL file trong repo\n    base_url = f\"https://huggingface.co/{repo_id}/resolve/main\"\n    return f\"{base_url}/{path_in_repo}\"\n\ndef process_video(gpu_id, video_queue, token):\n    device = torch.device(f\"cuda:{gpu_id}\")\n    print(f\"üöÄ Worker GPU {gpu_id} started\")\n\n    # Load model\n    tokenizer = XLMRobertaTokenizer(\"/kaggle/input/beit3_base_retrieval/pytorch/default/2/beit3.spm\")\n    ckpt = \"/kaggle/input/beit3_base_retrieval/pytorch/default/2/beit3_large_patch16_384_coco_retrieval.pth\"\n    model = beit3_large_patch16_384_retrieval(pretrained=False)\n    state_dict = torch.load(ckpt, map_location=device)\n    model.load_state_dict(state_dict[\"model\"], strict=False)\n    model = model.to(device).eval()\n\n    # Transform\n    transform  = transforms.Compose([\n        transforms.Resize((384, 384), interpolation=3), \n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n    ])\n\n    while True:\n        try:\n            video_path = video_queue.get(timeout=5)   # ch·ªù t·ªëi ƒëa 5s\n        except Exception:\n            print(f\"‚úÖ GPU {gpu_id} done (no more videos).\")\n            break\n\n        vid_name = os.path.splitext(os.path.basename(video_path))[0]\n        save_dir = f\"/kaggle/working/frames_{vid_name}\"\n        output_path = f\"/kaggle/working/embeddings/{vid_name}\"\n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n\n        print(f\"üé¨ GPU {gpu_id} processing {vid_name}\")\n\n        try:\n            dataset = VideoFrameDataset(video_path=video_path, save_dir=save_dir, transform=transform)\n            # dataset.frame_paths = dataset.frame_paths[:1000]\n            \n            embeddings, ids = extract_embeddings_dataloader(\n                dataset, model, transform, device, batch_size=64, num_workers=4\n            )\n            \n            # üëâ convert sang float16 ƒë·ªÉ ti·∫øt ki·ªám dung l∆∞·ª£ng\n            embeddings = embeddings.half().cpu()\n\n            io = EmbeddingIO(default_fmt=\"pkl\")\n            file_save = io.save(embeddings, output_path)\n            huggingface_dir = os.path.basename(os.path.dirname(os.path.dirname(video_path)))\n            \n            path_in_repo = os.path.join(huggingface_dir, os.path.basename(file_save))\n            print(path_in_repo)\n            repo_id = 'AIC3HUIT/AIC_2025'\n            for i in range(3):\n                try:\n                    upload_embeddings(local_file=file_save, \n                                           path_in_repo=path_in_repo,\n                                           repo_id=repo_id, \n                                            token=token)\n                    print(f\"ƒê·∫©y file {file_save} th√†nh c√¥ng l√™n huggingface\")\n                except:\n                    print(f\"ƒê·∫©y file {file_save} b·ªã l·ªói... ƒêang th·ª≠ l·∫°i l·∫ßn {i}\")\n                    time.sleep(1 + i)\n        except Exception as e:\n            print(f\"L·ªói khi x·ª≠ l√Ω {video_path} {e}\")\n        finally:\n            # lu√¥n xo√° frames folder sau khi x·ª≠ l√Ω\n            shutil.rmtree(save_dir, ignore_errors=True)\n            print(f\"üóëÔ∏è Deleted frames folder: {save_dir}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:06:33.403519Z","iopub.execute_input":"2025-09-05T11:06:33.403826Z","iopub.status.idle":"2025-09-05T11:06:33.413379Z","shell.execute_reply.started":"2025-09-05T11:06:33.403804Z","shell.execute_reply":"2025-09-05T11:06:33.412620Z"}},"outputs":[{"name":"stdout","text":"Overwriting multi_gpu_extract.py\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"# L∆∞u Embeddings","metadata":{}},{"cell_type":"code","source":"%%writefile embedding_io.py\nimport torch\nimport pickle\n\nclass EmbeddingIO:\n    def __init__(self, default_fmt: str = \"pkl\"):\n        \"\"\"\n        Class ƒë·ªÉ l∆∞u / load embeddings.\n        Args:\n            default_fmt (str): ƒë·ªãnh d·∫°ng m·∫∑c ƒë·ªãnh (\"pkl\" ho·∫∑c \"pt\")\n        \"\"\"\n        self.default_fmt = default_fmt.lower()\n\n    def save(self, embeddings, file_path: str, fmt: str = None):\n        \"\"\"\n        L∆∞u embeddings ra file pkl ho·∫∑c pt.\n        Args:\n            embeddings: torch.Tensor ho·∫∑c numpy.ndarray\n            file_path (str): ƒë∆∞·ªùng d·∫´n file (kh√¥ng c·∫ßn ƒëu√¥i)\n            fmt (str): \"pkl\" ho·∫∑c \"pt\". N·∫øu None -> d√πng default_fmt\n        \"\"\"\n        fmt = (fmt or self.default_fmt).lower()\n        if fmt == \"pkl\":\n            file_path = file_path + \".pkl\"\n            with open(file_path, \"wb\") as f:\n                pickle.dump(embeddings, f)\n            print(f\"‚úÖ Saved {file_path}\")\n        elif fmt == \"pt\":\n            file_path = file_path + \".pt\"\n            torch.save(embeddings, file_path)\n            print(f\"‚úÖ Saved {file_path}\")\n        else:\n            raise ValueError(\"fmt ph·∫£i l√† 'pkl' ho·∫∑c 'pt'\")\n        return file_path\n\n    def load(self, file_path: str, fmt: str = None):\n        \"\"\"\n        Load embeddings t·ª´ file pkl ho·∫∑c pt.\n        Args:\n            file_path (str): ƒë∆∞·ªùng d·∫´n file (kh√¥ng c·∫ßn ƒëu√¥i)\n            fmt (str): \"pkl\" ho·∫∑c \"pt\". N·∫øu None -> d√πng default_fmt\n        Returns:\n            torch.Tensor ho·∫∑c numpy.ndarray\n        \"\"\"\n        fmt = (fmt or self.default_fmt).lower()\n        if fmt == \"pkl\":\n            with open(file_path + \".pkl\", \"rb\") as f:\n                return pickle.load(f)\n        elif fmt == \"pt\":\n            return torch.load(file_path + \".pt\")\n        else:\n            raise ValueError(\"fmt ph·∫£i l√† 'pkl' ho·∫∑c 'pt'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:38.967408Z","iopub.execute_input":"2025-09-05T10:30:38.967732Z","iopub.status.idle":"2025-09-05T10:30:38.982473Z","shell.execute_reply.started":"2025-09-05T10:30:38.967709Z","shell.execute_reply":"2025-09-05T10:30:38.981937Z"}},"outputs":[{"name":"stdout","text":"Writing embedding_io.py\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Push Embedding","metadata":{}},{"cell_type":"code","source":"%%writefile hf_uploader.py\n\nfrom huggingface_hub import HfApi\n\n\nclass HFUploader:\n    def __init__(self, token: str = None):\n        \"\"\"\n        Kh·ªüi t·∫°o uploader.\n        N·∫øu c√≥ token -> d√πng ƒë·ªÉ x√°c minh.\n        \"\"\"\n        self.api = HfApi()\n        self.token = token\n\n    def upload_file(self, local_path: str, repo_id: str, path_in_repo: str = None, repo_type: str = \"model\"):\n        \"\"\"\n        Upload m·ªôt file l√™n Hugging Face.\n        \"\"\"\n        if path_in_repo is None:\n            import os\n            path_in_repo = os.path.basename(local_path)\n\n        return self.api.upload_file(\n            path_or_fileobj=local_path,\n            path_in_repo=path_in_repo,\n            repo_id=repo_id,\n            repo_type=repo_type,\n            token=self.token\n        )\n\n    def upload_folder(self, local_folder: str, repo_id: str, repo_type: str = \"dataset\", path_in_repo: str = \"\"):\n        \"\"\"\n        Upload m·ªôt th∆∞ m·ª•c l√™n Hugging Face, c√≥ th·ªÉ ch·ªâ ƒë·ªãnh th∆∞ m·ª•c con trong repo.\n        \"\"\"\n        return self.api.upload_folder(\n            folder_path=local_folder,\n            path_in_repo=path_in_repo,   # th∆∞ m·ª•c con trong repo, vd: \"data/\"\n            repo_id=repo_id,\n            repo_type=repo_type,\n            token=self.token\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:38.983201Z","iopub.execute_input":"2025-09-05T10:30:38.983483Z","iopub.status.idle":"2025-09-05T10:30:38.998864Z","shell.execute_reply.started":"2025-09-05T10:30:38.983456Z","shell.execute_reply":"2025-09-05T10:30:38.998295Z"}},"outputs":[{"name":"stdout","text":"Writing hf_uploader.py\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Prepare video path file","metadata":{}},{"cell_type":"code","source":"import os\nimport math\n\nclass VideoPathPrepare:\n    VIDEO_EXTENSIONS = {\".mp4\", \".avi\", \".mov\", \".mkv\", \".flv\", \".wmv\", \".webm\"}\n\n    def __init__(self, root_dirs, mode=\"subdir\"):\n        \"\"\"\n        Args:\n            root_dirs (str ho·∫∑c list[str]): 1 ho·∫∑c nhi·ªÅu th∆∞ m·ª•c\n            mode (str): \n                - \"subdir\": root_dirs ch·ª©a nhi·ªÅu th∆∞ m·ª•c con \"Videos*\"\n                - \"root\": root_dirs ch√≠nh l√† th∆∞ m·ª•c ch·ª©a video\n        \"\"\"\n        if isinstance(root_dirs, str):\n            root_dirs = [root_dirs]\n        self.root_dirs = root_dirs\n\n        if mode not in {\"subdir\", \"root\"}:\n            raise ValueError(\"mode ph·∫£i l√† 'subdir' ho·∫∑c 'root'\")\n        self.mode = mode\n\n        self.videos = self._list_videos()\n\n    def _list_videos(self):\n        video_files = []\n        for root_dir in self.root_dirs:\n            if self.mode == \"subdir\":\n                # üîπ T√¨m th∆∞ m·ª•c con 'Videos*'\n                subdirs = [\n                    d for d in os.listdir(root_dir)\n                    if os.path.isdir(os.path.join(root_dir, d)) and d.startswith(\"Videos\")\n                ]\n                subdirs.sort(key=str.lower)\n\n                for subdir in subdirs:\n                    full_path = os.path.join(root_dir, subdir)\n                    for root, _, files in os.walk(full_path):\n                        for file in sorted(files):\n                            ext = os.path.splitext(file)[1].lower()\n                            if ext in self.VIDEO_EXTENSIONS:\n                                video_files.append(os.path.join(root, file))\n\n            elif self.mode == \"root\":\n                # üîπ L·∫•y video trong root_dir v√† t·∫•t c·∫£ subdir b√™n trong\n                for root, _, files in os.walk(root_dir):\n                    for file in sorted(files):\n                        ext = os.path.splitext(file)[1].lower()\n                        if ext in self.VIDEO_EXTENSIONS:\n                            video_files.append(os.path.join(root, file))\n\n        return sorted(video_files)\n\n    def split_into_n_batches(self, n_batches):\n        \"\"\"Chia list video th√†nh n_batches (c√†ng ƒë·ªÅu c√†ng t·ªët).\"\"\"\n        total = len(self.videos)\n        if n_batches <= 0:\n            raise ValueError(\"S·ªë batch ph·∫£i > 0\")\n        if total == 0:\n            return []\n\n        batch_size = math.ceil(total / n_batches)\n        batches = []\n        for i in range(0, total, batch_size):\n            batches.append(self.videos[i:i + batch_size])\n        return batches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:38.999702Z","iopub.execute_input":"2025-09-05T10:30:38.999949Z","iopub.status.idle":"2025-09-05T10:30:39.015869Z","shell.execute_reply.started":"2025-09-05T10:30:38.999919Z","shell.execute_reply":"2025-09-05T10:30:39.015307Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Th·ª±c thi","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ntoken = user_secrets.get_secret(\"huggingface\")\n\nfolder_path = '/kaggle/input/aic2025-batch-2'\nprepare = VideoPathPrepare(folder_path, mode = 'subdir')\n\nprint(f\"T·ªïng s·ªë video: {len(prepare.videos)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:39.018004Z","iopub.execute_input":"2025-09-05T10:30:39.018172Z","iopub.status.idle":"2025-09-05T10:30:40.018598Z","shell.execute_reply.started":"2025-09-05T10:30:39.018158Z","shell.execute_reply":"2025-09-05T10:30:40.017986Z"}},"outputs":[{"name":"stdout","text":"T·ªïng s·ªë video: 605\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from multi_gpu_extract import process_video\nimport os\nif __name__ == \"__main__\":\n    mp.set_start_method(\"spawn\", force=True)\n    video_list = prepare.videos[204:221]\n    \n    # Queue\n    video_queue = mp.Manager().Queue()\n    for v in video_list:\n        video_queue.put(v)\n        \n    processes = []\n    for gpu_id in [1, 0]:\n        p = mp.Process(target=process_video, args=(gpu_id, video_queue, token))\n        p.start()\n        processes.append(p)\n    \n    for p in processes:\n        p.join()\n    \n    print(\"üéâ All videos processed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:06:57.313043Z","iopub.execute_input":"2025-09-05T11:06:57.313846Z"}},"outputs":[{"name":"stdout","text":"üöÄ Worker GPU 1 started\nüé¨ GPU 1 processing K07_V023\nüöÄ Worker GPU 0 started\nüé¨ GPU 0 processing K07_V022\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V023.mp4:   0%|          | 9/26220 [00:00<15:32, 28.10it/s]\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V022.mp4:   0%|          | 9/35918 [00:00<20:56, 28.59it/s]\nüîÑ Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]/kaggle/working/unilm/beit3/multi_gpu_extract.py:181: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n/kaggle/working/unilm/beit3/multi_gpu_extract.py:181: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:27<00:00, 27.56s/it]\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:27<00:00, 27.74s/it]\nNo files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V024.mp4:   0%|          | 2/29265 [00:00<24:44, 19.71it/s]","output_type":"stream"},{"name":"stdout","text":"Th·ªùi gian extract embedding: 27.55874514579773\n‚úÖ Saved /kaggle/working/embeddings/K07_V022.pkl\nVideos_K07/K07_V022.pkl\nüóëÔ∏è Deleted frames folder: /kaggle/working/frames_K07_V022\nüé¨ GPU 0 processing K07_V024\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V024.mp4:   0%|          | 9/29265 [00:00<12:27, 39.15it/s]\nüîÑ Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]No files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V025.mp4:   0%|          | 0/31836 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Th·ªùi gian extract embedding: 27.744462490081787\n‚úÖ Saved /kaggle/working/embeddings/K07_V023.pkl\nVideos_K07/K07_V023.pkl\nƒê·∫©y file /kaggle/working/embeddings/K07_V023.pkl b·ªã l·ªói... ƒêang th·ª≠ l·∫°i l·∫ßn 1\nüóëÔ∏è Deleted frames folder: /kaggle/working/frames_K07_V023\nüé¨ GPU 1 processing K07_V025\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V025.mp4:   0%|          | 9/31836 [00:00<31:40, 16.75it/s]  \nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:25<00:00, 25.96s/it]\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:25<00:00, 25.39s/it]\nNo files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V026.mp4:   0%|          | 0/35062 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Th·ªùi gian extract embedding: 25.955710649490356\n‚úÖ Saved /kaggle/working/embeddings/K07_V024.pkl\nVideos_K07/K07_V024.pkl\nüóëÔ∏è Deleted frames folder: /kaggle/working/frames_K07_V024\nüé¨ GPU 0 processing K07_V026\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V026.mp4:   0%|          | 9/35062 [00:00<14:10, 41.22it/s]\nüîÑ Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V027.mp4:   0%|          | 0/24155 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Th·ªùi gian extract embedding: 25.39354181289673\n‚úÖ Saved /kaggle/working/embeddings/K07_V025.pkl\nVideos_K07/K07_V025.pkl\nüóëÔ∏è Deleted frames folder: /kaggle/working/frames_K07_V025\nüé¨ GPU 1 processing K07_V027\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V027.mp4:   0%|          | 9/24155 [00:00<26:54, 14.95it/s]\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:25<00:00, 25.23s/it]\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:24<00:00, 24.86s/it]\nNo files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V028.mp4:   0%|          | 0/22570 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Th·ªùi gian extract embedding: 25.229962825775146\n‚úÖ Saved /kaggle/working/embeddings/K07_V026.pkl\nVideos_K07/K07_V026.pkl\nüóëÔ∏è Deleted frames folder: /kaggle/working/frames_K07_V026\nüé¨ GPU 0 processing K07_V028\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V028.mp4:   0%|          | 9/22570 [00:00<09:50, 38.23it/s]\nüîÑ Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V029.mp4:   0%|          | 0/35013 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Th·ªùi gian extract embedding: 24.862966299057007\n‚úÖ Saved /kaggle/working/embeddings/K07_V027.pkl\nVideos_K07/K07_V027.pkl\nüóëÔ∏è Deleted frames folder: /kaggle/working/frames_K07_V027\nüé¨ GPU 1 processing K07_V029\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V029.mp4:   0%|          | 9/35013 [00:00<28:30, 20.47it/s]\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:24<00:00, 24.87s/it]\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:23<00:00, 23.66s/it]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:25<00:00, 25.36s/it]\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V030.mp4:   0%|          | 0/27599 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Th·ªùi gian extract embedding: 24.867822885513306\n‚úÖ Saved /kaggle/working/embeddings/K07_V028.pkl\nVideos_K07/K07_V028.pkl\nüóëÔ∏è Deleted frames folder: /kaggle/working/frames_K07_V028\nüé¨ GPU 0 processing K07_V030\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V030.mp4:   0%|          | 9/27599 [00:00<11:43, 39.22it/s]\nüîÑ Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V031.mp4:   0%|          | 0/31732 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Th·ªùi gian extract embedding: 25.36093044281006\n‚úÖ Saved /kaggle/working/embeddings/K07_V029.pkl\nVideos_K07/K07_V029.pkl\nüóëÔ∏è Deleted frames folder: /kaggle/working/frames_K07_V029\nüé¨ GPU 1 processing K07_V031\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V031.mp4:   0%|          | 9/31732 [00:00<28:15, 18.71it/s]  \nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:24<00:00, 24.65s/it]\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:22<00:00, 22.85s/it]No files have been modified since last commit. Skipping to prevent empty commit.\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:24<00:00, 24.52s/it]\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V001.mp4:   0%|          | 0/33760 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Th·ªùi gian extract embedding: 24.64812707901001\n‚úÖ Saved /kaggle/working/embeddings/K07_V030.pkl\nVideos_K07/K07_V030.pkl\nüóëÔ∏è Deleted frames folder: /kaggle/working/frames_K07_V030\nüé¨ GPU 0 processing K08_V001\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V001.mp4:   0%|          | 9/33760 [00:00<16:34, 33.93it/s]\nüîÑ Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V002.mp4:   0%|          | 2/33835 [00:00<31:33, 17.86it/s]","output_type":"stream"},{"name":"stdout","text":"Th·ªùi gian extract embedding: 24.523205518722534\n‚úÖ Saved /kaggle/working/embeddings/K07_V031.pkl\nVideos_K07/K07_V031.pkl\nüóëÔ∏è Deleted frames folder: /kaggle/working/frames_K07_V031\nüé¨ GPU 1 processing K08_V002\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V002.mp4:   0%|          | 9/33835 [00:00<31:44, 17.76it/s]\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:24<00:00, 24.81s/it]\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:23<00:00, 23.10s/it]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:24<00:00, 24.84s/it]   | 0/34191 [00:00<?, ?it/s]\nExtracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V003.mp4:   0%|          | 3/34191 [00:00<21:55, 25.98it/s]","output_type":"stream"},{"name":"stdout","text":"Th·ªùi gian extract embedding: 24.809475898742676\n‚úÖ Saved /kaggle/working/embeddings/K08_V001.pkl\nVideos_K08/K08_V001.pkl\nüóëÔ∏è Deleted frames folder: /kaggle/working/frames_K08_V001\nüé¨ GPU 0 processing K08_V003\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V003.mp4:   0%|          | 9/34191 [00:00<15:54, 35.81it/s]\nüîÑ Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V004.mp4:   0%|          | 0/32168 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Th·ªùi gian extract embedding: 24.84357762336731\n‚úÖ Saved /kaggle/working/embeddings/K08_V002.pkl\nVideos_K08/K08_V002.pkl\nüóëÔ∏è Deleted frames folder: /kaggle/working/frames_K08_V002\nüé¨ GPU 1 processing K08_V004\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V004.mp4:   0%|          | 9/32168 [00:00<24:26, 21.93it/s]\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:24<00:00, 24.90s/it]\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:23<00:00, 23.06s/it]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nüîÑ Extracting embeddings (DataLoader): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:24<00:00, 24.73s/it]   | 0/29336 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Th·ªùi gian extract embedding: 24.898885250091553\n‚úÖ Saved /kaggle/working/embeddings/K08_V003.pkl\nVideos_K08/K08_V003.pkl\nüóëÔ∏è Deleted frames folder: /kaggle/working/frames_K08_V003\nüé¨ GPU 0 processing K08_V005\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V005.mp4:   0%|          | 9/29336 [00:00<12:03, 40.53it/s]\nüîÑ Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]","output_type":"stream"}],"execution_count":null}]}