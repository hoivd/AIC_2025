{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12779183,"sourceType":"datasetVersion","datasetId":8079103},{"sourceId":12858514,"sourceType":"datasetVersion","datasetId":8129235},{"sourceId":12858811,"sourceType":"datasetVersion","datasetId":8133250},{"sourceId":545126,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":418001,"modelId":435667}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Clone Source Code","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/hein-nkhh/unilm.git\n%cd unilm/beit3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:28:44.426216Z","iopub.execute_input":"2025-09-05T10:28:44.426856Z","iopub.status.idle":"2025-09-05T10:28:48.633900Z","shell.execute_reply.started":"2025-09-05T10:28:44.426823Z","shell.execute_reply":"2025-09-05T10:28:48.633056Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'unilm'...\nremote: Enumerating objects: 11122, done.\u001b[K\nremote: Counting objects: 100% (43/43), done.\u001b[K\nremote: Compressing objects: 100% (25/25), done.\u001b[K\nremote: Total 11122 (delta 31), reused 18 (delta 18), pack-reused 11079 (from 4)\u001b[K\nReceiving objects: 100% (11122/11122), 75.39 MiB | 35.87 MiB/s, done.\nResolving deltas: 100% (5248/5248), done.\n/kaggle/working/unilm/beit3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Import thư viện","metadata":{}},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:28:48.635603Z","iopub.execute_input":"2025-09-05T10:28:48.635832Z","iopub.status.idle":"2025-09-05T10:30:27.192991Z","shell.execute_reply.started":"2025-09-05T10:28:48.635811Z","shell.execute_reply":"2025-09-05T10:30:27.192305Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.21.0+cu124)\nCollecting timm==0.4.12 (from -r requirements.txt (line 3))\n  Downloading timm-0.4.12-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (11.2.1)\nRequirement already satisfied: blobfile in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.0.0)\nCollecting mypy (from -r requirements.txt (line 6))\n  Downloading mypy-1.17.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.2 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\nRequirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (8.3.5)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.32.4)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.8.1)\nCollecting tensorboardX (from -r requirements.txt (line 11))\n  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.15.3)\nCollecting ftfy (from -r requirements.txt (line 13))\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (4.11.0.86)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.2.0)\nRequirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (19.0.1)\nCollecting torchmetrics==0.7.3 (from -r requirements.txt (line 17))\n  Downloading torchmetrics-0.7.3-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (4.52.4)\nCollecting deepspeed==0.4.0 (from -r requirements.txt (line 19))\n  Downloading deepspeed-0.4.0.tar.gz (444 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.6/444.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (2.0.10)\nCollecting pycocoevalcap (from -r requirements.txt (line 21))\n  Downloading pycocoevalcap-1.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting torchscale==0.2.0 (from -r requirements.txt (line 22))\n  Downloading torchscale-0.2.0.tar.gz (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting pyDeprecate==0.3.* (from torchmetrics==0.7.3->-r requirements.txt (line 17))\n  Downloading pyDeprecate-0.3.2-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchmetrics==0.7.3->-r requirements.txt (line 17)) (25.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.4.0->-r requirements.txt (line 19)) (4.67.1)\nCollecting tensorboardX (from -r requirements.txt (line 11))\n  Downloading tensorboardX-1.8-py2.py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.4.0->-r requirements.txt (line 19)) (1.11.1.4)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.4.0->-r requirements.txt (line 19)) (7.0.0)\nRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 11)) (3.20.3)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tensorboardX->-r requirements.txt (line 11)) (1.17.0)\nCollecting fairscale==0.4.0 (from torchscale==0.2.0->-r requirements.txt (line 22))\n  Downloading fairscale-0.4.0.tar.gz (190 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.11/dist-packages (from blobfile->-r requirements.txt (line 5)) (3.23.0)\nRequirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile->-r requirements.txt (line 5)) (2.5.0)\nRequirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile->-r requirements.txt (line 5)) (5.4.0)\nRequirement already satisfied: mypy_extensions>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from mypy->-r requirements.txt (line 6)) (1.1.0)\nCollecting pathspec>=0.9.0 (from mypy->-r requirements.txt (line 6))\n  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 7)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 7)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 7)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 7)) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 7)) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 7)) (2.4.1)\nRequirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->-r requirements.txt (line 8)) (2.1.0)\nRequirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->-r requirements.txt (line 8)) (1.6.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 9)) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 9)) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 9)) (2025.6.15)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->-r requirements.txt (line 13)) (0.2.13)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 18)) (0.33.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 18)) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 18)) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 18)) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 18)) (0.5.3)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->-r requirements.txt (line 18)) (1.1.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 7)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 7)) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->-r requirements.txt (line 7)) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->-r requirements.txt (line 7)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->-r requirements.txt (line 7)) (2024.2.0)\nDownloading timm-0.4.12-py3-none-any.whl (376 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.2/398.2 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboardX-1.8-py2.py3-none-any.whl (216 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.3/216.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mypy-1.17.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (12.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\nBuilding wheels for collected packages: deepspeed, torchscale, fairscale\n  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for deepspeed: filename=deepspeed-0.4.0-py3-none-any.whl size=447148 sha256=9109332809f792617595fa7fab87430cfe2877838bae1a7e46971aded334302d\n  Stored in directory: /root/.cache/pip/wheels/2d/6c/59/e857be62a098db02f6b10d035ce825b949319643b75fcbbf03\n  Building wheel for torchscale (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for torchscale: filename=torchscale-0.2.0-py3-none-any.whl size=59731 sha256=99b51bd7e27c79ed02fde5d81a7ede3e7d874a7595b86d7a7e624d39dbe9fb32\n  Stored in directory: /root/.cache/pip/wheels/e4/a9/44/64be4b42608e466d86c5643f325670dc0761b698b9e847c0d2\n  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for fairscale: filename=fairscale-0.4.0-py3-none-any.whl size=240019 sha256=2cf40c1e89e069c2a94f897dcd1139970f54713f0da74b539b6a25e9a8d14068\n  Stored in directory: /root/.cache/pip/wheels/64/0d/d8/80dd4e467a3870f694ad9399e7ac0fcdc8ab78d828501a3193\nSuccessfully built deepspeed torchscale fairscale\nInstalling collected packages: pyDeprecate, pathspec, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, mypy, nvidia-cusolver-cu12, fairscale, timm, tensorboardX, torchscale, torchmetrics, pycocoevalcap, deepspeed\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.15\n    Uninstalling timm-1.0.15:\n      Successfully uninstalled timm-1.0.15\n  Attempting uninstall: torchmetrics\n    Found existing installation: torchmetrics 1.7.3\n    Uninstalling torchmetrics-1.7.3:\n      Successfully uninstalled torchmetrics-1.7.3\nSuccessfully installed deepspeed-0.4.0 fairscale-0.4.0 ftfy-6.3.1 mypy-1.17.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pathspec-0.12.1 pyDeprecate-0.3.2 pycocoevalcap-1.2 tensorboardX-1.8 timm-0.4.12 torchmetrics-0.7.3 torchscale-0.2.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\nimport time\nimport pickle\nimport torch\nfrom IPython.display import clear_output\nimport os\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer\nfrom modeling_finetune import beit3_large_patch16_384_retrieval\nfrom PIL import Image\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom torch.cuda.amp import autocast\nfrom transformers import XLMRobertaTokenizer\nimport json\nimport cv2\nfrom huggingface_hub import HfApi\nimport math\nimport torch.multiprocessing as mp\nfrom torch.utils.data import Dataset, DataLoader\nimport os\nimport time\nimport json\nimport cv2\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    XLMRobertaTokenizer\n)\nfrom modeling_finetune import beit3_large_patch16_384_retrieval\nfrom PIL import Image\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm, notebook\nimport shutil\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:27.194319Z","iopub.execute_input":"2025-09-05T10:30:27.194525Z","iopub.status.idle":"2025-09-05T10:30:38.881565Z","shell.execute_reply.started":"2025-09-05T10:30:27.194504Z","shell.execute_reply":"2025-09-05T10:30:38.880740Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import logging\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n    force=True,                 # ép ghi đè cấu hình cũ (rất quan trọng trong notebook)\n)\n\nlogger = logging.getLogger(\"Embedd Frame\")\nlogger.info(\"Xin chào\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:38.883122Z","iopub.execute_input":"2025-09-05T10:30:38.883513Z","iopub.status.idle":"2025-09-05T10:30:38.888670Z","shell.execute_reply.started":"2025-09-05T10:30:38.883492Z","shell.execute_reply":"2025-09-05T10:30:38.888127Z"}},"outputs":[{"name":"stderr","text":"2025-09-05 10:30:38,885 - Embedd Frame - INFO - Xin chào\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Cài đặt Device Torch","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:38.889485Z","iopub.execute_input":"2025-09-05T10:30:38.889783Z","iopub.status.idle":"2025-09-05T10:30:38.951235Z","shell.execute_reply.started":"2025-09-05T10:30:38.889766Z","shell.execute_reply":"2025-09-05T10:30:38.950543Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Extract Embedding","metadata":{}},{"cell_type":"code","source":"%%writefile multi_gpu_extract.py\nimport os\nimport av\nimport time\nimport json\nimport cv2\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    XLMRobertaTokenizer\n)\nfrom modeling_finetune import beit3_large_patch16_384_retrieval\nfrom PIL import Image\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm, notebook\nimport shutil\nfrom embedding_io import EmbeddingIO\nfrom hf_uploader import HFUploader\n\n# class VideoFrameDataset(Dataset):\n#     def __init__(self, video_path, save_dir=\"frames\", transform=None, show_progress=True):\n#         \"\"\"\n#         Dataset cho một video duy nhất, preload toàn bộ frame ra ảnh và trả về path.\n\n#         Args:\n#             video_path (str): đường dẫn đến file video\n#             save_dir (str): thư mục lưu frame\n#             transform: torchvision transforms áp dụng khi load frame\n#             show_progress (bool): có hiển thị tqdm progress bar hay không\n#         \"\"\"\n#         self.video_path = video_path\n#         self.save_dir = save_dir\n#         self.transform = transform\n#         self.frame_paths = []\n\n#         os.makedirs(self.save_dir, exist_ok=True)\n\n#         cap = cv2.VideoCapture(self.video_path)\n#         if not cap.isOpened():\n#             raise ValueError(f\"⚠️ Error loading video: {self.video_path}\")\n\n#         total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # tổng số frame\n#         pbar = tqdm(total=total_frames, desc=f\"Extracting {video_path}\", disable=not show_progress)\n\n#         idx = 0\n#         while True:\n#             ret, frame = cap.read()\n#             if not ret:\n#                 break\n#             frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n#             # path lưu frame\n#             frame_path = os.path.join(self.save_dir, f\"frame_{idx:06d}.jpg\")\n#             cv2.imwrite(frame_path, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))  # lưu lại dưới dạng jpg\n#             self.frame_paths.append(frame_path)\n\n#             idx += 1\n#             if idx == 2:\n#                 break\n#             pbar.update(1)\n\n#         cap.release()\n#         pbar.close()\n\n\n#         if len(self.frame_paths) == 0:\n#             raise ValueError(f\"⚠️ No frames extracted from video: {self.video_path}\")\n\n#     def __len__(self):\n#         return len(self.frame_paths)\n\n#     def __getitem__(self, idx):\n#         frame_path = self.frame_paths[idx]\n\n#         if self.transform:\n#             import PIL.Image\n#             img = PIL.Image.open(frame_path).convert(\"RGB\")\n#             img = self.transform(img)\n#             return img, frame_path\n\n#         return frame_path\n\nimport os\nfrom torch.utils.data import Dataset\nfrom tqdm import tqdm\nimport av\nfrom PIL import Image\n\nclass VideoFrameDataset(Dataset):\n    def __init__(self, video_path, save_dir=\"frames\", transform=None, show_progress=True):\n        \"\"\"\n        Dataset cho một video duy nhất, preload toàn bộ frame ra ảnh và trả về path.\n\n        Args:\n            video_path (str): đường dẫn đến file video\n            save_dir (str): thư mục lưu frame\n            transform: torchvision transforms áp dụng khi load frame\n            show_progress (bool): có hiển thị tqdm progress bar hay không\n        \"\"\"\n        self.video_path = video_path\n        self.save_dir = save_dir\n        self.transform = transform\n        self.frame_paths = []\n\n        os.makedirs(self.save_dir, exist_ok=True)\n\n        try:\n            container = av.open(self.video_path)\n        except av.AVError as e:\n            raise ValueError(f\"⚠️ Error loading video: {self.video_path}\\n{e}\")\n\n        total_frames = container.streams.video[0].frames\n        pbar = tqdm(total=total_frames, desc=f\"Extracting {video_path}\", disable=not show_progress)\n\n        idx = 0\n        for frame in container.decode(video=0):\n            img = frame.to_image()  # PIL Image\n            frame_path = os.path.join(self.save_dir, f\"frame_{idx:06d}.jpg\")\n            img.save(frame_path)\n            self.frame_paths.append(frame_path)\n            idx += 1\n            if idx == 10:\n                break\n            pbar.update(1)\n\n        pbar.close()\n\n        if len(self.frame_paths) == 0:\n            raise ValueError(f\"⚠️ No frames extracted from video: {self.video_path}\")\n\n    def __len__(self):\n        return len(self.frame_paths)\n\n    def __getitem__(self, idx):\n        frame_path = self.frame_paths[idx]\n\n        if self.transform:\n            img = Image.open(frame_path).convert(\"RGB\")\n            img = self.transform(img)\n            return img, frame_path\n\n        return frame_path\n\ndef collate_fn(batch):\n    \"\"\"Bỏ qua sample lỗi (None)\"\"\"\n    batch = [x for x in batch if x[0] is not None]\n    if not batch:\n        return None, None\n    images, paths = zip(*batch)\n    return torch.stack(images, dim=0), list(paths)\n\ndef extract_embeddings_dataloader(dataset, model, transform, device, batch_size=64, num_workers=4):\n    dataloader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        collate_fn=collate_fn,\n        prefetch_factor=3,\n        pin_memory=True\n    )\n\n    embeddings = []\n    ids = []\n\n    model.eval()\n    start_extract_embedding = time.time()\n\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"🔄 Extracting embeddings (DataLoader)\"):\n            batch_tensor, batch_ids = batch\n            if batch_tensor is None:\n                continue\n\n            batch_tensor = batch_tensor.to(device, non_blocking=True)\n\n            with autocast():\n                vision_cls_batch = model(image=batch_tensor, only_infer=True)[0]  # (B, D)\n                vision_norm_batch = F.normalize(vision_cls_batch, p=2, dim=-1)\n\n            embeddings.extend([emb.cpu() for emb in vision_norm_batch])\n            ids.extend(batch_ids)\n\n            del batch_tensor, vision_cls_batch, vision_norm_batch\n            torch.cuda.empty_cache()\n\n    image_embeddings = torch.stack(embeddings, dim=0)\n    end_extract_embedding = time.time()\n    print(f\"Thời gian extract embedding: {end_extract_embedding-start_extract_embedding}\")\n\n    return image_embeddings, ids\n\ndef upload_embeddings(local_file: str, repo_id: str, token: str,\n                       repo_type: str = \"dataset\", path_in_repo: str = None):\n    \"\"\"\n    Upload một file từ local lên Hugging Face repo và trả về URL trong repo.\n    Args:\n        local_file: đường dẫn file ở local\n        repo_id: repo_id trên Hugging Face (vd: \"username/my-dataset\")\n        token: Hugging Face token\n        repo_type: loại repo (\"model\", \"dataset\", \"space\")\n        path_in_repo: đường dẫn lưu trong repo (mặc định = tên file)\n    \"\"\"\n    uploader = HFUploader(token=token)\n    uploader.upload_file(\n        local_path=local_file,\n        repo_id=repo_id,\n        repo_type=repo_type,\n        path_in_repo=path_in_repo\n    )\n\n    if path_in_repo is None:\n        import os\n        path_in_repo = os.path.basename(local_file)\n\n    # URL file trong repo\n    base_url = f\"https://huggingface.co/{repo_id}/resolve/main\"\n    return f\"{base_url}/{path_in_repo}\"\n\ndef process_video(gpu_id, video_queue, token):\n    device = torch.device(f\"cuda:{gpu_id}\")\n    print(f\"🚀 Worker GPU {gpu_id} started\")\n\n    # Load model\n    tokenizer = XLMRobertaTokenizer(\"/kaggle/input/beit3_base_retrieval/pytorch/default/2/beit3.spm\")\n    ckpt = \"/kaggle/input/beit3_base_retrieval/pytorch/default/2/beit3_large_patch16_384_coco_retrieval.pth\"\n    model = beit3_large_patch16_384_retrieval(pretrained=False)\n    state_dict = torch.load(ckpt, map_location=device)\n    model.load_state_dict(state_dict[\"model\"], strict=False)\n    model = model.to(device).eval()\n\n    # Transform\n    transform  = transforms.Compose([\n        transforms.Resize((384, 384), interpolation=3), \n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n    ])\n\n    while True:\n        try:\n            video_path = video_queue.get(timeout=5)   # chờ tối đa 5s\n        except Exception:\n            print(f\"✅ GPU {gpu_id} done (no more videos).\")\n            break\n\n        vid_name = os.path.splitext(os.path.basename(video_path))[0]\n        save_dir = f\"/kaggle/working/frames_{vid_name}\"\n        output_path = f\"/kaggle/working/embeddings/{vid_name}\"\n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n\n        print(f\"🎬 GPU {gpu_id} processing {vid_name}\")\n\n        try:\n            dataset = VideoFrameDataset(video_path=video_path, save_dir=save_dir, transform=transform)\n            # dataset.frame_paths = dataset.frame_paths[:1000]\n            \n            embeddings, ids = extract_embeddings_dataloader(\n                dataset, model, transform, device, batch_size=64, num_workers=4\n            )\n            \n            # 👉 convert sang float16 để tiết kiệm dung lượng\n            embeddings = embeddings.half().cpu()\n\n            io = EmbeddingIO(default_fmt=\"pkl\")\n            file_save = io.save(embeddings, output_path)\n            huggingface_dir = os.path.basename(os.path.dirname(os.path.dirname(video_path)))\n            \n            path_in_repo = os.path.join(huggingface_dir, os.path.basename(file_save))\n            print(path_in_repo)\n            repo_id = 'AIC3HUIT/AIC_2025'\n            for i in range(3):\n                try:\n                    upload_embeddings(local_file=file_save, \n                                           path_in_repo=path_in_repo,\n                                           repo_id=repo_id, \n                                            token=token)\n                    print(f\"Đẩy file {file_save} thành công lên huggingface\")\n                except:\n                    print(f\"Đẩy file {file_save} bị lỗi... Đang thử lại lần {i}\")\n                    time.sleep(1 + i)\n        except Exception as e:\n            print(f\"Lỗi khi xử lý {video_path} {e}\")\n        finally:\n            # luôn xoá frames folder sau khi xử lý\n            shutil.rmtree(save_dir, ignore_errors=True)\n            print(f\"🗑️ Deleted frames folder: {save_dir}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:06:33.403519Z","iopub.execute_input":"2025-09-05T11:06:33.403826Z","iopub.status.idle":"2025-09-05T11:06:33.413379Z","shell.execute_reply.started":"2025-09-05T11:06:33.403804Z","shell.execute_reply":"2025-09-05T11:06:33.412620Z"}},"outputs":[{"name":"stdout","text":"Overwriting multi_gpu_extract.py\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"# Lưu Embeddings","metadata":{}},{"cell_type":"code","source":"%%writefile embedding_io.py\nimport torch\nimport pickle\n\nclass EmbeddingIO:\n    def __init__(self, default_fmt: str = \"pkl\"):\n        \"\"\"\n        Class để lưu / load embeddings.\n        Args:\n            default_fmt (str): định dạng mặc định (\"pkl\" hoặc \"pt\")\n        \"\"\"\n        self.default_fmt = default_fmt.lower()\n\n    def save(self, embeddings, file_path: str, fmt: str = None):\n        \"\"\"\n        Lưu embeddings ra file pkl hoặc pt.\n        Args:\n            embeddings: torch.Tensor hoặc numpy.ndarray\n            file_path (str): đường dẫn file (không cần đuôi)\n            fmt (str): \"pkl\" hoặc \"pt\". Nếu None -> dùng default_fmt\n        \"\"\"\n        fmt = (fmt or self.default_fmt).lower()\n        if fmt == \"pkl\":\n            file_path = file_path + \".pkl\"\n            with open(file_path, \"wb\") as f:\n                pickle.dump(embeddings, f)\n            print(f\"✅ Saved {file_path}\")\n        elif fmt == \"pt\":\n            file_path = file_path + \".pt\"\n            torch.save(embeddings, file_path)\n            print(f\"✅ Saved {file_path}\")\n        else:\n            raise ValueError(\"fmt phải là 'pkl' hoặc 'pt'\")\n        return file_path\n\n    def load(self, file_path: str, fmt: str = None):\n        \"\"\"\n        Load embeddings từ file pkl hoặc pt.\n        Args:\n            file_path (str): đường dẫn file (không cần đuôi)\n            fmt (str): \"pkl\" hoặc \"pt\". Nếu None -> dùng default_fmt\n        Returns:\n            torch.Tensor hoặc numpy.ndarray\n        \"\"\"\n        fmt = (fmt or self.default_fmt).lower()\n        if fmt == \"pkl\":\n            with open(file_path + \".pkl\", \"rb\") as f:\n                return pickle.load(f)\n        elif fmt == \"pt\":\n            return torch.load(file_path + \".pt\")\n        else:\n            raise ValueError(\"fmt phải là 'pkl' hoặc 'pt'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:38.967408Z","iopub.execute_input":"2025-09-05T10:30:38.967732Z","iopub.status.idle":"2025-09-05T10:30:38.982473Z","shell.execute_reply.started":"2025-09-05T10:30:38.967709Z","shell.execute_reply":"2025-09-05T10:30:38.981937Z"}},"outputs":[{"name":"stdout","text":"Writing embedding_io.py\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Push Embedding","metadata":{}},{"cell_type":"code","source":"%%writefile hf_uploader.py\n\nfrom huggingface_hub import HfApi\n\n\nclass HFUploader:\n    def __init__(self, token: str = None):\n        \"\"\"\n        Khởi tạo uploader.\n        Nếu có token -> dùng để xác minh.\n        \"\"\"\n        self.api = HfApi()\n        self.token = token\n\n    def upload_file(self, local_path: str, repo_id: str, path_in_repo: str = None, repo_type: str = \"model\"):\n        \"\"\"\n        Upload một file lên Hugging Face.\n        \"\"\"\n        if path_in_repo is None:\n            import os\n            path_in_repo = os.path.basename(local_path)\n\n        return self.api.upload_file(\n            path_or_fileobj=local_path,\n            path_in_repo=path_in_repo,\n            repo_id=repo_id,\n            repo_type=repo_type,\n            token=self.token\n        )\n\n    def upload_folder(self, local_folder: str, repo_id: str, repo_type: str = \"dataset\", path_in_repo: str = \"\"):\n        \"\"\"\n        Upload một thư mục lên Hugging Face, có thể chỉ định thư mục con trong repo.\n        \"\"\"\n        return self.api.upload_folder(\n            folder_path=local_folder,\n            path_in_repo=path_in_repo,   # thư mục con trong repo, vd: \"data/\"\n            repo_id=repo_id,\n            repo_type=repo_type,\n            token=self.token\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:38.983201Z","iopub.execute_input":"2025-09-05T10:30:38.983483Z","iopub.status.idle":"2025-09-05T10:30:38.998864Z","shell.execute_reply.started":"2025-09-05T10:30:38.983456Z","shell.execute_reply":"2025-09-05T10:30:38.998295Z"}},"outputs":[{"name":"stdout","text":"Writing hf_uploader.py\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Prepare video path file","metadata":{}},{"cell_type":"code","source":"import os\nimport math\n\nclass VideoPathPrepare:\n    VIDEO_EXTENSIONS = {\".mp4\", \".avi\", \".mov\", \".mkv\", \".flv\", \".wmv\", \".webm\"}\n\n    def __init__(self, root_dirs, mode=\"subdir\"):\n        \"\"\"\n        Args:\n            root_dirs (str hoặc list[str]): 1 hoặc nhiều thư mục\n            mode (str): \n                - \"subdir\": root_dirs chứa nhiều thư mục con \"Videos*\"\n                - \"root\": root_dirs chính là thư mục chứa video\n        \"\"\"\n        if isinstance(root_dirs, str):\n            root_dirs = [root_dirs]\n        self.root_dirs = root_dirs\n\n        if mode not in {\"subdir\", \"root\"}:\n            raise ValueError(\"mode phải là 'subdir' hoặc 'root'\")\n        self.mode = mode\n\n        self.videos = self._list_videos()\n\n    def _list_videos(self):\n        video_files = []\n        for root_dir in self.root_dirs:\n            if self.mode == \"subdir\":\n                # 🔹 Tìm thư mục con 'Videos*'\n                subdirs = [\n                    d for d in os.listdir(root_dir)\n                    if os.path.isdir(os.path.join(root_dir, d)) and d.startswith(\"Videos\")\n                ]\n                subdirs.sort(key=str.lower)\n\n                for subdir in subdirs:\n                    full_path = os.path.join(root_dir, subdir)\n                    for root, _, files in os.walk(full_path):\n                        for file in sorted(files):\n                            ext = os.path.splitext(file)[1].lower()\n                            if ext in self.VIDEO_EXTENSIONS:\n                                video_files.append(os.path.join(root, file))\n\n            elif self.mode == \"root\":\n                # 🔹 Lấy video trong root_dir và tất cả subdir bên trong\n                for root, _, files in os.walk(root_dir):\n                    for file in sorted(files):\n                        ext = os.path.splitext(file)[1].lower()\n                        if ext in self.VIDEO_EXTENSIONS:\n                            video_files.append(os.path.join(root, file))\n\n        return sorted(video_files)\n\n    def split_into_n_batches(self, n_batches):\n        \"\"\"Chia list video thành n_batches (càng đều càng tốt).\"\"\"\n        total = len(self.videos)\n        if n_batches <= 0:\n            raise ValueError(\"Số batch phải > 0\")\n        if total == 0:\n            return []\n\n        batch_size = math.ceil(total / n_batches)\n        batches = []\n        for i in range(0, total, batch_size):\n            batches.append(self.videos[i:i + batch_size])\n        return batches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:38.999702Z","iopub.execute_input":"2025-09-05T10:30:38.999949Z","iopub.status.idle":"2025-09-05T10:30:39.015869Z","shell.execute_reply.started":"2025-09-05T10:30:38.999919Z","shell.execute_reply":"2025-09-05T10:30:39.015307Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Thực thi","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ntoken = user_secrets.get_secret(\"huggingface\")\n\nfolder_path = '/kaggle/input/aic2025-batch-2'\nprepare = VideoPathPrepare(folder_path, mode = 'subdir')\n\nprint(f\"Tổng số video: {len(prepare.videos)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T10:30:39.018004Z","iopub.execute_input":"2025-09-05T10:30:39.018172Z","iopub.status.idle":"2025-09-05T10:30:40.018598Z","shell.execute_reply.started":"2025-09-05T10:30:39.018158Z","shell.execute_reply":"2025-09-05T10:30:40.017986Z"}},"outputs":[{"name":"stdout","text":"Tổng số video: 605\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from multi_gpu_extract import process_video\nimport os\nif __name__ == \"__main__\":\n    mp.set_start_method(\"spawn\", force=True)\n    video_list = prepare.videos[204:221]\n    \n    # Queue\n    video_queue = mp.Manager().Queue()\n    for v in video_list:\n        video_queue.put(v)\n        \n    processes = []\n    for gpu_id in [1, 0]:\n        p = mp.Process(target=process_video, args=(gpu_id, video_queue, token))\n        p.start()\n        processes.append(p)\n    \n    for p in processes:\n        p.join()\n    \n    print(\"🎉 All videos processed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T11:06:57.313043Z","iopub.execute_input":"2025-09-05T11:06:57.313846Z"}},"outputs":[{"name":"stdout","text":"🚀 Worker GPU 1 started\n🎬 GPU 1 processing K07_V023\n🚀 Worker GPU 0 started\n🎬 GPU 0 processing K07_V022\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V023.mp4:   0%|          | 9/26220 [00:00<15:32, 28.10it/s]\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V022.mp4:   0%|          | 9/35918 [00:00<20:56, 28.59it/s]\n🔄 Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]/kaggle/working/unilm/beit3/multi_gpu_extract.py:181: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n/kaggle/working/unilm/beit3/multi_gpu_extract.py:181: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:27<00:00, 27.56s/it]\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:27<00:00, 27.74s/it]\nNo files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V024.mp4:   0%|          | 2/29265 [00:00<24:44, 19.71it/s]","output_type":"stream"},{"name":"stdout","text":"Thời gian extract embedding: 27.55874514579773\n✅ Saved /kaggle/working/embeddings/K07_V022.pkl\nVideos_K07/K07_V022.pkl\n🗑️ Deleted frames folder: /kaggle/working/frames_K07_V022\n🎬 GPU 0 processing K07_V024\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V024.mp4:   0%|          | 9/29265 [00:00<12:27, 39.15it/s]\n🔄 Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]No files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V025.mp4:   0%|          | 0/31836 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Thời gian extract embedding: 27.744462490081787\n✅ Saved /kaggle/working/embeddings/K07_V023.pkl\nVideos_K07/K07_V023.pkl\nĐẩy file /kaggle/working/embeddings/K07_V023.pkl bị lỗi... Đang thử lại lần 1\n🗑️ Deleted frames folder: /kaggle/working/frames_K07_V023\n🎬 GPU 1 processing K07_V025\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V025.mp4:   0%|          | 9/31836 [00:00<31:40, 16.75it/s]  \n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:25<00:00, 25.96s/it]\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:25<00:00, 25.39s/it]\nNo files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V026.mp4:   0%|          | 0/35062 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Thời gian extract embedding: 25.955710649490356\n✅ Saved /kaggle/working/embeddings/K07_V024.pkl\nVideos_K07/K07_V024.pkl\n🗑️ Deleted frames folder: /kaggle/working/frames_K07_V024\n🎬 GPU 0 processing K07_V026\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V026.mp4:   0%|          | 9/35062 [00:00<14:10, 41.22it/s]\n🔄 Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V027.mp4:   0%|          | 0/24155 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Thời gian extract embedding: 25.39354181289673\n✅ Saved /kaggle/working/embeddings/K07_V025.pkl\nVideos_K07/K07_V025.pkl\n🗑️ Deleted frames folder: /kaggle/working/frames_K07_V025\n🎬 GPU 1 processing K07_V027\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V027.mp4:   0%|          | 9/24155 [00:00<26:54, 14.95it/s]\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:25<00:00, 25.23s/it]\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:24<00:00, 24.86s/it]\nNo files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V028.mp4:   0%|          | 0/22570 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Thời gian extract embedding: 25.229962825775146\n✅ Saved /kaggle/working/embeddings/K07_V026.pkl\nVideos_K07/K07_V026.pkl\n🗑️ Deleted frames folder: /kaggle/working/frames_K07_V026\n🎬 GPU 0 processing K07_V028\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V028.mp4:   0%|          | 9/22570 [00:00<09:50, 38.23it/s]\n🔄 Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V029.mp4:   0%|          | 0/35013 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Thời gian extract embedding: 24.862966299057007\n✅ Saved /kaggle/working/embeddings/K07_V027.pkl\nVideos_K07/K07_V027.pkl\n🗑️ Deleted frames folder: /kaggle/working/frames_K07_V027\n🎬 GPU 1 processing K07_V029\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V029.mp4:   0%|          | 9/35013 [00:00<28:30, 20.47it/s]\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:24<00:00, 24.87s/it]\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:23<00:00, 23.66s/it]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:25<00:00, 25.36s/it]\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V030.mp4:   0%|          | 0/27599 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Thời gian extract embedding: 24.867822885513306\n✅ Saved /kaggle/working/embeddings/K07_V028.pkl\nVideos_K07/K07_V028.pkl\n🗑️ Deleted frames folder: /kaggle/working/frames_K07_V028\n🎬 GPU 0 processing K07_V030\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V030.mp4:   0%|          | 9/27599 [00:00<11:43, 39.22it/s]\n🔄 Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V031.mp4:   0%|          | 0/31732 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Thời gian extract embedding: 25.36093044281006\n✅ Saved /kaggle/working/embeddings/K07_V029.pkl\nVideos_K07/K07_V029.pkl\n🗑️ Deleted frames folder: /kaggle/working/frames_K07_V029\n🎬 GPU 1 processing K07_V031\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K07/video/K07_V031.mp4:   0%|          | 9/31732 [00:00<28:15, 18.71it/s]  \n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:24<00:00, 24.65s/it]\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:22<00:00, 22.85s/it]No files have been modified since last commit. Skipping to prevent empty commit.\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:24<00:00, 24.52s/it]\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V001.mp4:   0%|          | 0/33760 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Thời gian extract embedding: 24.64812707901001\n✅ Saved /kaggle/working/embeddings/K07_V030.pkl\nVideos_K07/K07_V030.pkl\n🗑️ Deleted frames folder: /kaggle/working/frames_K07_V030\n🎬 GPU 0 processing K08_V001\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V001.mp4:   0%|          | 9/33760 [00:00<16:34, 33.93it/s]\n🔄 Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V002.mp4:   0%|          | 2/33835 [00:00<31:33, 17.86it/s]","output_type":"stream"},{"name":"stdout","text":"Thời gian extract embedding: 24.523205518722534\n✅ Saved /kaggle/working/embeddings/K07_V031.pkl\nVideos_K07/K07_V031.pkl\n🗑️ Deleted frames folder: /kaggle/working/frames_K07_V031\n🎬 GPU 1 processing K08_V002\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V002.mp4:   0%|          | 9/33835 [00:00<31:44, 17.76it/s]\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:24<00:00, 24.81s/it]\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:23<00:00, 23.10s/it]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:24<00:00, 24.84s/it]   | 0/34191 [00:00<?, ?it/s]\nExtracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V003.mp4:   0%|          | 3/34191 [00:00<21:55, 25.98it/s]","output_type":"stream"},{"name":"stdout","text":"Thời gian extract embedding: 24.809475898742676\n✅ Saved /kaggle/working/embeddings/K08_V001.pkl\nVideos_K08/K08_V001.pkl\n🗑️ Deleted frames folder: /kaggle/working/frames_K08_V001\n🎬 GPU 0 processing K08_V003\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V003.mp4:   0%|          | 9/34191 [00:00<15:54, 35.81it/s]\n🔄 Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\nExtracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V004.mp4:   0%|          | 0/32168 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Thời gian extract embedding: 24.84357762336731\n✅ Saved /kaggle/working/embeddings/K08_V002.pkl\nVideos_K08/K08_V002.pkl\n🗑️ Deleted frames folder: /kaggle/working/frames_K08_V002\n🎬 GPU 1 processing K08_V004\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V004.mp4:   0%|          | 9/32168 [00:00<24:26, 21.93it/s]\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:24<00:00, 24.90s/it]\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:23<00:00, 23.06s/it]No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\n🔄 Extracting embeddings (DataLoader): 100%|██████████| 1/1 [00:24<00:00, 24.73s/it]   | 0/29336 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Thời gian extract embedding: 24.898885250091553\n✅ Saved /kaggle/working/embeddings/K08_V003.pkl\nVideos_K08/K08_V003.pkl\n🗑️ Deleted frames folder: /kaggle/working/frames_K08_V003\n🎬 GPU 0 processing K08_V005\n","output_type":"stream"},{"name":"stderr","text":"Extracting /kaggle/input/aic2025-batch-2/Videos_K08/video/K08_V005.mp4:   0%|          | 9/29336 [00:00<12:03, 40.53it/s]\n🔄 Extracting embeddings (DataLoader):   0%|          | 0/1 [00:00<?, ?it/s]","output_type":"stream"}],"execution_count":null}]}