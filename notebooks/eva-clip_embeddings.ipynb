{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12779183,"sourceType":"datasetVersion","datasetId":8079103},{"sourceId":12833107,"sourceType":"datasetVersion","datasetId":8111258},{"sourceId":12858514,"sourceType":"datasetVersion","datasetId":8129235}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from PIL import Image\nfrom transformers import AutoModel, AutoConfig\nfrom transformers import CLIPImageProcessor, pipeline, CLIPTokenizer\nimport torch\nimport torchvision.transforms as T\nfrom torchvision.transforms import InterpolationMode\nimport pickle\nfrom torch.nn.functional import cosine_similarity\nimport torch\nimport pickle\nfrom tqdm import tqdm\nimport json\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom IPython.display import clear_output\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-26T07:35:32.253786Z","iopub.execute_input":"2025-08-26T07:35:32.254396Z","iopub.status.idle":"2025-08-26T07:41:19.493916Z","shell.execute_reply.started":"2025-08-26T07:35:32.254368Z","shell.execute_reply":"2025-08-26T07:41:19.492265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_name_or_path = \"BAAI/EVA-CLIP-8B\"\nimage_size = 224\n\nmodel = AutoModel.from_pretrained(\n    model_name_or_path,\n    torch_dtype=torch.float16,\n    trust_remote_code=True\n).eval()\n\nprocessor = CLIPImageProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\ntokenizer = CLIPTokenizer.from_pretrained(model_name_or_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Mô hình translate\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n\nmodel_name = \"VietAI/envit5-translation\"\ntokenizer_translate = AutoTokenizer.from_pretrained(model_name)  \nmodel_translate = AutoModelForSeq2SeqLM.from_pretrained(model_name)\nmodel_translate = model_translate.to('cuda:0')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T07:41:19.497326Z","iopub.execute_input":"2025-08-26T07:41:19.497580Z","iopub.status.idle":"2025-08-26T07:41:30.915367Z","shell.execute_reply.started":"2025-08-26T07:41:19.497562Z","shell.execute_reply":"2025-08-26T07:41:30.909819Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_model = model.text_model.to(\"cuda:0\") \nvision_model = model.vision_model.to(\"cuda:1\")  \nmodel.visual_projection = model.visual_projection.to(\"cuda:1\")  \nmodel.text_projection = model.text_projection.to(\"cuda:0\")  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T07:41:30.916268Z","iopub.execute_input":"2025-08-26T07:41:30.917084Z","iopub.status.idle":"2025-08-26T07:41:37.951114Z","shell.execute_reply.started":"2025-08-26T07:41:30.917049Z","shell.execute_reply":"2025-08-26T07:41:37.950541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_image(image_path):\n    image = Image.open(image_path).convert(\"RGB\")\n    inputs = processor(images=image, return_tensors=\"pt\").to('cuda:1')\n    return inputs['pixel_values'] \n\ndef preprocess_text(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to('cuda:0')\n    return inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T07:41:40.940440Z","iopub.execute_input":"2025-08-26T07:41:40.940641Z","iopub.status.idle":"2025-08-26T07:41:40.944846Z","shell.execute_reply.started":"2025-08-26T07:41:40.940624Z","shell.execute_reply":"2025-08-26T07:41:40.944157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_image_features(image_path):\n    pixel_values = preprocess_image(image_path)  \n    with torch.no_grad(), torch.cuda.amp.autocast():  \n        image_features = model.encode_image(pixel_values).to('cuda:0')\n    image_features /= image_features.norm(dim=-1, keepdim=True)  \n    return image_features\n\n\ndef get_text_features(text):\n    text_inputs = preprocess_text(text)  \n    with torch.no_grad(), torch.cuda.amp.autocast(): \n        text_features = model.encode_text(text_inputs['input_ids']).to('cuda:0')\n    text_features /= text_features.norm(dim=-1, keepdim=True) \n    return text_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T07:41:40.955987Z","iopub.execute_input":"2025-08-26T07:41:40.956226Z","iopub.status.idle":"2025-08-26T07:41:40.965904Z","shell.execute_reply.started":"2025-08-26T07:41:40.956209Z","shell.execute_reply":"2025-08-26T07:41:40.965253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def translate_vi_en(text: str) -> str:\n    # Thêm prefix \"vi:\" vào input\n    prefixed = f\"vi: {text}\"\n    inputs = tokenizer_translate([prefixed], return_tensors=\"pt\", padding=True).input_ids.to('cuda:0')\n    outputs = model_translate.generate(inputs, max_length=50)\n    translated = tokenizer_translate.decode(outputs[0], skip_special_tokens=True)\n    # Xóa prefix \"en:\" nếu có\n    return translated.replace(\"en:\", \"\").strip()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from torch.nn.functional import cosine_similarity\n# import re\n\n# # Hàm tìm kiếm ảnh phù hợp với văn bản\n# def text_to_image_retrieval(text, image_paths):\n#     text_features = get_text_features(text)\n    \n#     similarities = []\n#     for image_path in image_paths:\n#         image_features = get_image_features(image_path)\n#         similarity = cosine_similarity(text_features, image_features)\n#         similarities.append((image_path, similarity.item()))\n    \n#     # Sắp xếp theo độ tương đồng giảm dần\n#     similarities.sort(key=lambda x: x[1], reverse=True)\n    \n#     return similarities\n\n# # Thử với một văn bản\n# text_query = \"Cháy rừng\"\n# text_query_en = translate_vi_en(text_query)\n# retrieved_images = text_to_image_retrieval(text_query_en, image_paths)\n\n# # In ảnh có độ tương đồng cao nhất\n# print(\"Best matching images:\")\n\n# for i, (image_path, similarity) in enumerate(retrieved_images[:5]):\n#     print(f\"{image_path} with similarity: {similarity:.4f}\")\n    \n#     # Hiển thị ảnh\n#     img = Image.open(image_path)\n#     plt.figure(figsize=(8, 6))  # Kích thước hiển thị\n#     plt.imshow(np.array(img))   # Chuyển sang array để imshow xử lý\n#     plt.title(f\"Image: {image_path}\\nSimilarity: {similarity:.4f}\")\n#     plt.axis('off')  # Tắt trục tọa độ\n#     plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T07:56:28.360526Z","iopub.execute_input":"2025-08-26T07:56:28.360789Z","iopub.status.idle":"2025-08-26T07:56:28.364833Z","shell.execute_reply.started":"2025-08-26T07:56:28.360769Z","shell.execute_reply":"2025-08-26T07:56:28.364089Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"json_files = ['/kaggle/input/aic-sample-test/keyframes_index/L21_V003_keyframes_index.json',\n             '/kaggle/input/aic-sample-test/keyframes_index/L21_V006_keyframes_index.json',\n             '/kaggle/input/aic-sample-test/keyframes_index/L21_V007_keyframes_index.json',\n             '/kaggle/input/aic-sample-test/keyframes_index/L21_V011_keyframes_index.json'\n            ]\n\n\nvideo_paths = ['/kaggle/input/aic-sample-test/videos/L21_V003.mp4', \n               '/kaggle/input/aic-sample-test/videos/L21_V006.mp4',\n               '/kaggle/input/aic-sample-test/videos/L21_V007.mp4',\n               '/kaggle/input/aic-sample-test/videos/L21_V011.mp4'\n              ]\n\noutput_dir = 'extracted_frames'\nos.makedirs(output_dir, exist_ok=True)\n\nimage_paths = []\n\nfor i, json_file in enumerate(json_files):\n    with open(json_file, 'r') as f:\n        frame_indices = json.load(f)\n\n    cap = cv2.VideoCapture(video_paths[i])\n    \n    if not cap.isOpened():\n        print(f\"Không thể mở video: {video_paths[i]}\")\n        continue\n\n    # tqdm để hiển thị tiến trình\n    for frame_index in tqdm(frame_indices, desc=f\"Trích xuất từ video {i+1}/{len(json_files)}\"):\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n        ret, frame = cap.read()\n        if not ret:\n            print(f\"⚠️ Không thể đọc frame tại index {frame_index} trong video {i+1}.\")\n            continue\n\n        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        frame_image = Image.fromarray(frame_rgb)\n        \n        frame_path = os.path.join(output_dir, f'video{i+1}_frame_{frame_index}.png')\n        frame_image.save(frame_path)\n        image_paths.append(frame_path)\n\n    cap.release()\n    \nclear_output()\nprint(f\"Đã trích xuất tổng cộng {len(image_paths)} frame.\")\nprint(f\"Các đường dẫn frame:\", image_paths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T08:05:04.721944Z","iopub.execute_input":"2025-08-26T08:05:04.722534Z","iopub.status.idle":"2025-08-26T08:11:48.441203Z","shell.execute_reply.started":"2025-08-26T08:05:04.722512Z","shell.execute_reply":"2025-08-26T08:11:48.440257Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_image_embeddings(image_paths, save_path=\"image_embeddings.pkl\"):\n    image_embeddings = {}\n    for img_path in tqdm(image_paths, desc=\"Extracting image embeddings\"):\n        image_features = get_image_features(img_path)  # Hàm của bạn\n        # image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n        image_embeddings[img_path] = image_features.cpu()\n    \n    with open(save_path, \"wb\") as f:\n        pickle.dump(image_embeddings, f)\n\nbuild_image_embeddings(image_paths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T08:12:41.594113Z","iopub.execute_input":"2025-08-26T08:12:41.594803Z","iopub.status.idle":"2025-08-26T08:20:11.964189Z","shell.execute_reply.started":"2025-08-26T08:12:41.594775Z","shell.execute_reply":"2025-08-26T08:20:11.963613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def text_to_image_retrieval(text, embeddings_path=\"image_embeddings.pkl\"):\n    # Load embeddings đã lưu\n    with open(embeddings_path, \"rb\") as f:\n        image_embeddings = pickle.load(f)\n    \n    # Trích xuất text features\n    text_features = get_text_features(text).cpu()\n    # text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n\n    similarities = []\n    for img_path, img_feat in image_embeddings.items():\n        sim = cosine_similarity(text_features, img_feat)\n        similarities.append((img_path, sim.item()))\n    \n    similarities.sort(key=lambda x: x[1], reverse=True)\n    return similarities\n\n# Ví dụ\ntext_query = \"Hái chuối\"\ntext_query_en = translate_vi_en(text_query)\nretrieved_images = text_to_image_retrieval(text_query_en)\n\n\nfor i, (image_path, similarity) in enumerate(retrieved_images[:5]):\n    print(f\"{image_path} with similarity: {similarity:.4f}\")\n    \n    # Hiển thị ảnh\n    img = Image.open(image_path)\n    plt.figure(figsize=(8, 6))  # Kích thước hiển thị\n    plt.imshow(np.array(img))   # Chuyển sang array để imshow xử lý\n    plt.title(f\"Image: {image_path}\\nSimilarity: {similarity:.4f}\")\n    plt.axis('off')  # Tắt trục tọa độ\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T08:24:05.955523Z","iopub.execute_input":"2025-08-26T08:24:05.955772Z","iopub.status.idle":"2025-08-26T08:24:07.694589Z","shell.execute_reply.started":"2025-08-26T08:24:05.955755Z","shell.execute_reply":"2025-08-26T08:24:07.693836Z"}},"outputs":[],"execution_count":null}]}