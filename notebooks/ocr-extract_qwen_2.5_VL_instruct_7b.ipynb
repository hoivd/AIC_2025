{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12779183,"sourceType":"datasetVersion","datasetId":8079103}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T15:39:19.300237Z","iopub.execute_input":"2025-08-24T15:39:19.301104Z","iopub.status.idle":"2025-08-24T15:39:19.307020Z","shell.execute_reply.started":"2025-08-24T15:39:19.301066Z","shell.execute_reply":"2025-08-24T15:39:19.306456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers accelerate\n!pip install qwen-vl-utils[decord]==0.0.8\nclear_output()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T15:39:19.308236Z","iopub.execute_input":"2025-08-24T15:39:19.308445Z","iopub.status.idle":"2025-08-24T15:41:15.004822Z","shell.execute_reply.started":"2025-08-24T15:39:19.308420Z","shell.execute_reply":"2025-08-24T15:41:15.004041Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\nfrom qwen_vl_utils import process_vision_info\n\n# default: Load the model on the available device(s)\nmodel = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2.5-VL-7B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n)\n\n# default processer\n# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\nmin_pixels = 256 * 28 * 28\nmax_pixels = 1280 * 28 * 28\nprocessor = AutoProcessor.from_pretrained(\n    \"Qwen/Qwen2.5-VL-7B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T15:41:15.006256Z","iopub.execute_input":"2025-08-24T15:41:15.006464Z","iopub.status.idle":"2025-08-24T15:44:46.297812Z","shell.execute_reply.started":"2025-08-24T15:41:15.006442Z","shell.execute_reply":"2025-08-24T15:44:46.297147Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T15:44:46.298592Z","iopub.execute_input":"2025-08-24T15:44:46.299174Z","iopub.status.idle":"2025-08-24T15:44:46.303238Z","shell.execute_reply.started":"2025-08-24T15:44:46.299154Z","shell.execute_reply":"2025-08-24T15:44:46.302565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def infer_batch(image_paths: list[str], df: pd.DataFrame):\n    \"\"\"\n    Thực hiện OCR batch cho nhiều ảnh bằng model đã load sẵn.\n\n    Args:\n        image_paths (list[str]): danh sách đường dẫn ảnh cần OCR.\n\n    Returns:\n        list[str]: list các chuỗi văn bản OCR tương ứng với từng ảnh.\n    \"\"\"\n    # Tạo danh sách messages cho từng ảnh\n    all_messages = []\n    for img in image_paths:\n        messages = [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"image\",\n                        \"image\": img,\n                    },\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"\"\"Extract all text that is clearly visible and fully legible in the image.\n                        Crucially, only transcribe text that is completely unobstructed, uncovered, and not partially hidden by any other objects or elements within the image.\n                        Do not infer, guess, or hallucinate any text that is unclear, obscured, or not genuinely present.\n                        Only output text that is definitively and entirely legible.\n                        Present the extracted text line by line.\"\"\"\n                    },\n                ],\n            }\n        ] \n        all_messages.append(messages)\n\n    # Chuẩn bị input batch\n    texts = [\n        processor.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)\n        for msg in all_messages\n    ]\n    image_inputs, video_inputs = process_vision_info(all_messages)\n\n    inputs = processor(\n        text=texts,\n        images=image_inputs,\n        videos=video_inputs,\n        padding=True,\n        return_tensors=\"pt\",\n    ).to(\"cuda\")\n\n    # Batch inference\n    generated_ids = model.generate(\n        **inputs,\n        max_new_tokens=512,\n        do_sample=False,\n        temperature=0.0,\n        repetition_penalty=1.0,\n    )\n    generated_ids_trimmed = [\n        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n    ]\n    output_texts = processor.batch_decode(\n        generated_ids_trimmed,\n        skip_special_tokens=True,\n        clean_up_tokenization_spaces=False,\n    )\n\n    batch_df = pd.DataFrame({\n            \"image_path\": image_paths,\n            \"text_recognition\": [txt if txt else \"EMPTY\" for txt in output_texts]\n        })\n\n        # Dùng pd.concat để gộp batch với df hiện tại\n    df = pd.concat([df, batch_df], ignore_index=True)\n\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T15:44:46.304910Z","iopub.execute_input":"2025-08-24T15:44:46.305196Z","iopub.status.idle":"2025-08-24T15:44:46.325135Z","shell.execute_reply.started":"2025-08-24T15:44:46.305177Z","shell.execute_reply":"2025-08-24T15:44:46.324521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport time\nimport pandas as pd\n\nfile_name = os.listdir('/kaggle/input/aic-small-2024/Keyframes_L22/keyframes/L22_V002')\nfile_name = file_name[:22]\nlist_imgs = []\nfor i in range(len(file_name)):\n    list_imgs.append(os.path.join('/kaggle/input/aic-small-2024/Keyframes_L22/keyframes/L22_V002', file_name[i]))\n\ndf = pd.DataFrame(columns=[\"image_path\", \"text_recognition\"])\n\nbatch_size = 10\nstart = time.time()\n\nfor i in range(0, len(list_imgs), batch_size):\n    batch_imgs = list_imgs[i:i+batch_size] \n    df = infer_batch(batch_imgs, df) \n\nend = time.time()\n\n# In ra thời gian thực hiện\nprint(\"Time taken: \", end - start)\n\n# Sau khi xử lý tất cả ảnh, bạn có thể lưu kết quả vào file CSV\ndf.to_csv('ocr_output.csv', mode='a', header=False, index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T15:44:46.325871Z","iopub.execute_input":"2025-08-24T15:44:46.326103Z","iopub.status.idle":"2025-08-24T15:56:02.493083Z","shell.execute_reply.started":"2025-08-24T15:44:46.326068Z","shell.execute_reply":"2025-08-24T15:56:02.492443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['text_recognition'][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T15:56:02.494021Z","iopub.execute_input":"2025-08-24T15:56:02.494282Z","iopub.status.idle":"2025-08-24T15:56:02.526579Z","shell.execute_reply.started":"2025-08-24T15:56:02.494263Z","shell.execute_reply":"2025-08-24T15:56:02.526019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T15:56:02.527339Z","iopub.execute_input":"2025-08-24T15:56:02.527883Z","iopub.status.idle":"2025-08-24T15:56:02.574788Z","shell.execute_reply.started":"2025-08-24T15:56:02.527854Z","shell.execute_reply":"2025-08-24T15:56:02.574202Z"}},"outputs":[],"execution_count":null}]}