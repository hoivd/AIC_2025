{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12779183,"sourceType":"datasetVersion","datasetId":8079103}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sscarecrow/phowhisperforaic?scriptVersionId=258914893\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Libraries Install","metadata":{}},{"cell_type":"code","source":"!pip -q install \"transformers>=4.41\" \"accelerate>=0.30\" torch torchaudio soundfile librosa\n!ffmpeg -version >/dev/null 2>&1 || (apt-get -y update && apt-get -y install ffmpeg)\n!pip install -q transformers sentence-transformers torch accelerate einops","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T17:41:22.939932Z","iopub.execute_input":"2025-08-27T17:41:22.940179Z","iopub.status.idle":"2025-08-27T17:42:35.238264Z","shell.execute_reply.started":"2025-08-27T17:41:22.940154Z","shell.execute_reply":"2025-08-27T17:42:35.237456Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Libraries and Helper Functions","metadata":{}},{"cell_type":"code","source":"import os, json, math, subprocess\nfrom pathlib import Path\nfrom datetime import timedelta\nfrom typing import List, Dict, Any\nimport torch\nimport soundfile as sf\nimport librosa\nimport torch\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nimport numpy as np\nimport json\n\nINPUT_DIR  = \"/kaggle/working/videos\"        \nOUTPUT_DIR = \"/kaggle/working/transcripts\"   \nMODEL_ID   = \"vinai/PhoWhisper-large\"\nLANGUAGE   = \"vi\"\nAUDIO_SR = 16000\nAUDIO_CH = 1\nVIDEO_EXTS = {\".mp4\", \".mkv\", \".mov\", \".avi\", \".flv\", \".webm\"}\nAUDIO_EXTS = {\".wav\", \".mp3\", \".m4a\", \".aac\", \".flac\", \".ogg\", \".wma\"}\nPath(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\ndef run_cmd(cmd):\n    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n    if p.returncode != 0:\n        raise RuntimeError(f\"Command failed: {' '.join(cmd)}\\nSTDERR:\\n{p.stderr}\")\ndef has_stream_audio(input_path: str) -> bool:\n    try:\n        p = subprocess.run(\n            [\"ffprobe\",\"-v\",\"error\",\"-select_streams\",\"a\",\n             \"-show_entries\",\"stream=index\",\"-of\",\"csv=p=0\", input_path],\n            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n        )\n        return bool(p.stdout.strip())\n    except Exception:\n        return True\ndef extract_wav_16k_mono(input_media: str, out_wav: str) -> None:\n    cmd = [\n        \"ffmpeg\",\"-y\",\"-i\", input_media,\n        \"-vn\",\"-acodec\",\"pcm_s16le\",\n        \"-ar\", str(AUDIO_SR), \"-ac\", str(AUDIO_CH),\n        out_wav\n    ]\n    run_cmd(cmd)\ndef list_media_files(folder: str):\n    p = Path(folder)\n    files = []\n    for ext in list(VIDEO_EXTS | AUDIO_EXTS):\n        files.extend(p.rglob(f\"*{ext}\"))\n    return sorted(files)\ndef format_timestamp(seconds: float) -> str:\n    total_ms = int(seconds * 1000)\n    h = total_ms // 3_600_000\n    m = (total_ms % 3_600_000) // 60_000\n    s = (total_ms % 60_000) // 1000\n    ms = total_ms % 1000\n    return f\"{h:02d}:{m:02d}:{s:02d},{ms:03d}\"\ndef write_txt(path: str, full_text: str):\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        f.write(full_text.strip() + \"\\n\")\ndef write_json(path: str, segments: List[Dict[str,Any]], meta: Dict[str,Any]):\n    payload = {\n        \"meta\": meta,\n        \"segments\": segments,\n        \"text\": \" \".join(seg[\"text\"] for seg in segments).strip()\n    }\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(payload, f, ensure_ascii=False, indent=2)\ndef write_srt(path: str, segments: List[Dict[str,Any]]):\n    lines = []\n    for i, seg in enumerate(segments, 1):\n        lines += [str(i),\n                  f\"{format_timestamp(seg['start'])} --> {format_timestamp(seg['end'])}\",\n                  seg[\"text\"].strip(),\n                  \"\"]\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(lines))\n\nprint(\"Config loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T17:42:35.240126Z","iopub.execute_input":"2025-08-27T17:42:35.240739Z","iopub.status.idle":"2025-08-27T17:43:02.678319Z","shell.execute_reply.started":"2025-08-27T17:42:35.240704Z","shell.execute_reply":"2025-08-27T17:43:02.677582Z"}},"outputs":[{"name":"stderr","text":"2025-08-27 17:42:48.613658: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756316568.807763      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756316568.863558      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Config loaded.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Model (PhoWhisper)","metadata":{}},{"cell_type":"code","source":"from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq, pipeline\ndevice = 0 if torch.cuda.is_available() else -1\ndtype  = torch.float16 if torch.cuda.is_available() else torch.float32\nprocessor = AutoProcessor.from_pretrained(MODEL_ID)\nmodel = AutoModelForSpeechSeq2Seq.from_pretrained(\n    MODEL_ID,\n    torch_dtype=dtype,\n    low_cpu_mem_usage=True\n)\ngen = model.generation_config\ngen.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"vi\", task=\"transcribe\")\ngen.language = \"vi\"\ngen.task = \"transcribe\"\nmodel.generation_config = gen\nif device == 0:\n    model = model.to(\"cuda\")\nasr = pipeline(\n    task=\"automatic-speech-recognition\",\n    model=model,\n    tokenizer=processor.tokenizer,\n    feature_extractor=processor.feature_extractor,\n    device=device\n)\nprint(\"PhoWhisper loaded:\", MODEL_ID)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T17:43:02.679074Z","iopub.execute_input":"2025-08-27T17:43:02.679696Z","iopub.status.idle":"2025-08-27T17:43:54.455652Z","shell.execute_reply.started":"2025-08-27T17:43:02.679665Z","shell.execute_reply":"2025-08-27T17:43:54.454953Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/339 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a1ef4dab83f4a24a77a24119192f218"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/805 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a870659af1f4904ae8446b203a30e03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c6791a5fab44d7a9027371e0f068811"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11f3f61ded3842d68601ec74ec841650"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f3eee31c56f41f299fe1a502783c1d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"288b0cc508144fb7afc88397aed34d50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86fdefac56af4e68930b274365c4622b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eefeded487ce442399be04e69ed95e9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8e2192e9adc4eb396e5bf3a25d9802f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/6.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc2bac32925a42ea8e91795a98d9dd1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4b5d2c06c3b4f36915d580185b729fb"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"PhoWhisper loaded: vinai/PhoWhisper-large\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Extracting a file","metadata":{}},{"cell_type":"code","source":"SINGLE_INPUT = \"/kaggle/input/aic-small-2024/Videos_L22_a/video/L22_V002.mp4\" \nCUSTOM_NAME  = None                                  \nsrc = Path(SINGLE_INPUT)\nassert src.exists(), f\"Không tìm thấy file: {src}\"\nstem = CUSTOM_NAME if CUSTOM_NAME else src.stem\nout_base = Path(OUTPUT_DIR) / stem\nout_base.parent.mkdir(parents=True, exist_ok=True)\nwav_path  = str(out_base.with_suffix(\".wav\"))\ntxt_path  = str(out_base.with_suffix(\".txt\"))\njson_path = str(out_base.with_suffix(\".json\"))\nsrt_path  = str(out_base.with_suffix(\".srt\"))\nprint(f\"=== Xử lý 1 file: {src} ===\")\nif src.suffix.lower() in VIDEO_EXTS and not has_stream_audio(str(src)):\n    raise SystemExit(\"File không có audio stream. Không thể tạo transcript.\")\nextract_wav_16k_mono(str(src), wav_path)\nprint(\"-> Đã tách WAV 16k mono.\")\naudio, sr = librosa.load(wav_path, sr=AUDIO_SR, mono=True)\nresult = asr(\n    audio,                \n    return_timestamps=\"phrase\"  \n)\nfull_text = result[\"text\"].strip()\nsegments_out = []\nchunks = result.get(\"chunks\", None)\nif chunks:\n    for i, ck in enumerate(chunks):\n        start = float(ck[\"timestamp\"][0]) if ck[\"timestamp\"][0] is not None else 0.0\n        end   = float(ck[\"timestamp\"][1]) if ck[\"timestamp\"][1] is not None else max(start, 0.0)\n        segments_out.append({\n            \"id\": i,\n            \"start\": start,\n            \"end\": end,\n            \"text\": ck[\"text\"].strip()\n        })\nelse:\n    duration = librosa.get_duration(y=audio, sr=sr)\n    segments_out.append({\"id\": 0, \"start\": 0.0, \"end\": float(duration), \"text\": full_text})\nmeta = {\n    \"source\": str(src),\n    \"wav_16k_mono\": wav_path,\n    \"language\": LANGUAGE,\n    \"model\": MODEL_ID,\n    \"duration\": float(librosa.get_duration(y=audio, sr=sr))\n}\nwrite_txt(txt_path, full_text)\nwrite_json(json_path, segments_out, meta)\nwrite_srt(srt_path, segments_out)\nprint(f\"-> OK: {txt_path}\")\nprint(f\"-> OK: {json_path}\")\nprint(f\"-> OK: {srt_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T17:43:54.457356Z","iopub.execute_input":"2025-08-27T17:43:54.457846Z"}},"outputs":[{"name":"stdout","text":"=== Xử lý 1 file: /kaggle/input/aic-small-2024/Videos_L22_a/video/L22_V002.mp4 ===\n-> Đã tách WAV 16k mono.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n  warnings.warn(\nYou have passed task=transcribe, but also have set `forced_decoder_ids` to [(1, 50278), (2, 50359), (3, 50363)] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Extracting all files in a folder","metadata":{}},{"cell_type":"code","source":"# media_files = list_media_files(INPUT_DIR)\n# if not media_files:\n#     raise SystemExit(f\"Không tìm thấy video/audio trong: {INPUT_DIR}\")\n# print(f\"Đã tìm thấy {len(media_files)} tệp.\")\n# for src in media_files:\n#     src = Path(src)\n#     stem = src.stem\n#     out_base = Path(OUTPUT_DIR) / stem\n#     out_base.parent.mkdir(parents=True, exist_ok=True)\n#     wav_path  = str(out_base.with_suffix(\".wav\"))\n#     txt_path  = str(out_base.with_suffix(\".txt\"))\n#     json_path = str(out_base.with_suffix(\".json\"))\n#     srt_path  = str(out_base.with_suffix(\".srt\"))\n#     print(f\"\\n=== Xử lý: {src} ===\")\n#     if src.suffix.lower() in VIDEO_EXTS and not has_stream_audio(str(src)):\n#         print(\"-> Bỏ qua: file không có audio stream.\")\n#         continue\n#     extract_wav_16k_mono(str(src), wav_path)\n#     print(\"-> Đã tách WAV 16k mono.\")\n#     audio, sr = librosa.load(wav_path, sr=AUDIO_SR, mono=True)\n#     result = asr(\n#         audio,\n#         generate_kwargs={\"language\": LANGUAGE, \"task\": \"transcribe\"},\n#         return_timestamps=\"phrase\"\n#     )\n#     full_text = result[\"text\"].strip()\n#     segments_out = []\n#     chunks = result.get(\"chunks\", None)\n#     if chunks:\n#         for i, ck in enumerate(chunks):\n#             start = float(ck[\"timestamp\"][0]) if ck[\"timestamp\"][0] is not None else 0.0\n#             end   = float(ck[\"timestamp\"][1]) if ck[\"timestamp\"][1] is not None else max(start, 0.0)\n#             segments_out.append({\n#                 \"id\": i,\n#                 \"start\": start,\n#                 \"end\": end,\n#                 \"text\": ck[\"text\"].strip()\n#             })\n#     else:\n#         duration = librosa.get_duration(y=audio, sr=sr)\n#         segments_out.append({\"id\": 0, \"start\": 0.0, \"end\": float(duration), \"text\": full_text})\n\n#     meta = {\n#         \"source\": str(src),\n#         \"wav_16k_mono\": wav_path,\n#         \"language\": LANGUAGE,\n#         \"model\": MODEL_ID,\n#         \"duration\": float(librosa.get_duration(y=audio, sr=sr))\n#     }\n#     write_txt(txt_path, full_text)\n#     write_json(json_path, segments_out, meta)\n#     write_srt(srt_path, segments_out)\n\n#     print(f\"-> OK: {txt_path}\")\n#     print(f\"-> OK: {json_path}\")\n#     print(f\"-> OK: {srt_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}